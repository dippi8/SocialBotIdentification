% !TEX root = ../thesis.tex
\chapter{Features engineering}
\label{capitolo4}
\thispagestyle{empty}

This chapter can be seen as one of the most important of the whole project.

We wouldn't have hit such performances, if it wasn't for feature engineering. We had a large pool of models to pick for our purpose,  and we tried different assets for them, but the difference were made with the reasoning behind the construction of the final feature vector.

Twitter APIs provides us two kinds of features: the user attributes and the tweet attributes.
We knew that user attributes weren't enough to infer on targets, so we started planning how to include tweet informations and enhance our data with them. This was the bulk of the work, but it helped us to catch characteristic behaviors of some user.
We created many features. Some of them are descriptive, like the lenght of strings (name, description ecc) or the count (miminimum, maximum, average) of other aspects like hashtags per tweet and tweet's lenght. Features describing the tweeting activity (frequency, how often a tweet contains a media or a url or it is just a retweet) have been considered too.
Other kind of features are more behaviour-oriented, like the monotony of different tweets of the same user,while others are oriented to the most used words in tweets.
Finally we also added features related to image analysis.

The choice over the amount of tweets that would have been considered was a trade-off between performance and prediction speed.\\
We finally chose to retrive up to the latest 100 tweets for each user, because further material led us to a slower, but equivalent, prediction over test samples.\\
At the end of this stage, the resulting - and final - feature vector will include 38 features.

\section{Baseline}
In this section we analyse the complete set of default profile features and which kind of pre-processing operation we applied. With this default set we trained several classifiers to define some baselines for the upcoming work and this allowed us to evaluate the improvements made by the features engineering step.

Some features are ready to be used in a classifier, while other ones need to be pre-processed, in order to allow them to be more expressive.
We wanted to rely on user features only for this experiment, in order to have a large improvement margin to exploit, once we would have gone deeper in the study.

During the data exploration stage, we identified the most and least meaningful attributes to trace a baseline, so we started from that. We simply tried to improve and to homologate the features highlighted in the previous chapters.

We faced a lot of missing values as well as non-numeric ones.
Even if the goal was to build a raw model with semi-raw data, we needed feasible and manageable attributes to work with.

Her we list all the pre-processing operations applied to each feature belonging to the ones provided by the method \textit{get\_user()}, of the official Twitter APIs.
\newpage
\small
\begin{center}
	\begin{tabular}{lll}
		\\feature&type&preprocess operation\\
		\hline\hline
		id&int&delete - useless feature\\
		name&str&delete - non-numeric feature\\
		screen\_name&str&delete - non-numeric feature\\
		statuses\_count&int&---\\
		followers\_count&int&---\\
		friends\_count&int&---\\
		favourites\_count&int&---\\
		listed\_count&int&---\\
		url&str&replace with hasUrl (0/1)\\
		lang&str&delete - non-numeric feature\\
		time\_zone&str&delete - too many missing values\\
		location&str&delete - too many missing values\\
		default\_profile&int&delete - too many missing values\\
		default\_profile\_image&boolean&boolean to int (0/1)\\
		geo\_enabled&boolean&delete - too many missing values\\
		profile\_image\_url&str&delete - non-numeric feature\\
		profile\_use\_background\_image&boolean&boolean to int (0/1)\\
		profile\_background\_image\_url\_https&str&delete - non-numeric feature\\
		profile\_text\_color&str&delete - non-numeric feature\\
		profile\_image\_url\_https&str&delete - non-numeric feature\\
		profile\_sidebar\_border\_color&str&delete - non-numeric feature\\
		profile\_background\_tile&boolean&boolean to int (0/1)\\
		profile\_sidebar\_fill\_color&str&delete - non-numeric feature\\
		profile\_background\_image\_url&str&delete - non-numeric feature\\
		profile\_background\_color&str&delete - non-numeric feature\\
		profile\_link\_color&str&delete - non-numeric feature\\
		utc\_offset&int&delete - too many missing values\\
		is\_translator&boolean&delete - too many missing values\\
		follow\_request\_sent&int&delete - relative feature\\
		protected&boolean&delete - too many missing values\\
		verified&boolean&delete - too many missing values\\
		notifications&boolean&delete - relative feature\\
		description&str&replace with hasDescription (0/1)\\
		contributors\_enabled&boolean&delete - too many missing values\\
		following&boolean&delete - relative feature\\
		created\_at&str&delete - useless feature\\\hline\\
	\end{tabular}
\end{center}
\normalsize
Features processed as "delete - relative feature" are those ones related to the user who performed the scraping. So we didn't need them.

\section{Missing values filling}
Features with few missing values was not deleted from the dataset, but we needed to fill that fields.
In this section we analyze how we performed this task for each features.
\begin{itemize}
	\item[\PencilRight]\textbf{default\_profile\_image}: Thanks to the figure \ref{fig:msno} we could see that all the missing values was at the bottom, in particular, all of them was in tuples with target 3 or 4. In order to uderstand the behaviour of this feature, we printed its values count for each indicted target.
	\begin{center}
		\begin{tabular}{lll}
			\\target&3\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&2868\\
			1&228\\\hline\\
		\end{tabular}
		
		\begin{tabular}{lll}
			\\target&4\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&181\\
			1&19\\\hline\\
		\end{tabular}
	\end{center}
	
	In both cases the value "0" is more frequent then "1", so we filled al the missing values with the mode (0).
	
	\item[\PencilRight]\textbf{profile\_background\_tile}: As for "default\_profile\_image", all the missing values belonged to target 3 and 4. We used the same approach and we obtained:
	\begin{center}
		\begin{tabular}{lll}
			\\target&3\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&3086\\
			1&99\\\hline\\
		\end{tabular}
		
		\begin{tabular}{lll}
			\\target&4\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&1347\\
			1&147\\\hline\\
		\end{tabular}
	\end{center}
	In this case we decided to fill these fields with the mode (0). Since most of the data are 0, this choise allowed us not to dirty the dataset.
	
	
	\item[\PencilRight]\textbf{profile\_use\_background\_image}: All the missing values are still in the last two classes.
	\begin{center}
		\begin{tabular}{lll}
			\\target&3\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&12\\
			1&4983\\\hline\\
		\end{tabular}
		
		\begin{tabular}{lll}
			\\target&4\\
			\hline\hline
			value&mean\\
			\hline\hline
			0&25\\
			1&3246\\\hline\\
		\end{tabular}
	\end{center}
	This data is really unbalanced, so filling the null fields with the mode (1) is still the better solution.
	
\end{itemize}
\section{Descriptive features}

In order to enrich our attributes and to provide support to our algorithms, we decided to add some descriptive "meta" features, such as synthesis statistics and counters.

Their purpose is to describe the tweets in a statistical way, adding ranges and means to the attributes provided by the official APIs.\\
Each of these new values were been added to the users feature vector, in order to append new informations for each account.
Here is the list of this first 18 brand new features, introduced by our work:

\small
\begin{center}
	\begin{tabular}{ll}
		\\feature&description\\
		\hline\hline
		avg\_len&average lenght of the tweets (words)\\
		max\_len&lenght of the longest tweet (words)\\
		min\_len&lenght of the shortest tweet (words)\\
		avg\_ret&average amount of retweets (by other users) per tweet\\
		max\_ret&highest amount of retweets (by other users) on a tweet\\
		min\_ret&lowest amount of retweets (by other users) on a tweet\\
		avg\_fav&average amount of favourites (by other users) per tweet\\
		max\_fav&highest amount of favourites (by other users) on a tweet\\
		min\_fav&lowest amount of favourites (by other users) on a tweet\\
		avg\_hash&average amount of hashtags involved in tweets\\
		max\_hash&highest amount of hashtags involved on a tweet\\
		min\_hash&highest amount of hashtags involved on a tweet\\
		freq&amount of tweets per day (up to 100)\\
		ret\_perc&percentage of retweets, made by the user, over its retrieved tweets\\
		media\_perc&percentage of media content incorpored in tweets\\
		url\_perc&percentage of URL links placed inside tweets\\
		quote\_perc&percentage of quotes, made by the user, over its retrieved tweets\\\hline\\
	\end{tabular}
\end{center}
\normalsize

\section{Intrinsic features}
Due the multiclass nature of our dataset, it was impossible to rely on the descriptive meta features only.

We faced the need of better capturing some behaviours, that could have helped us distinguish between targets.\\
We spent a lot of time analysing Twitter timelines by ourselves. This was one of the most useful phases of our work.\\
Indeed, we have learnt a lot about bots acting like humans on the social platform.
One thing that was easy to notice was the monotony, in terms of words or URLs involved in tweets, met with Spam-bots, as well as the opposites, for Genuine accounts or Fake-Followers.

We tried to encapsule this distinctive behaviour by adding two intrinsic features to the training vector, along with the descriptive ones.\\

How to portray such monotony?\\
We though about different approaches, like complex sentiment analysis or entity recognition, but then, we chose to rely on a weighting technique and the euclidean distance.\\
We looked inside every retrieved tweets for each user, then we encoded each of them with TF-IDF weighting.\\

Every term (word) of every tweet was represented by a numeric weight, according to TF-IDF.\\
This weighting formula is a combination of Term Frequency (TF) and Inverse Document Frequency (IDF).
\[ TF_{i,j} =\frac {n_{i,j}}{|d_{j}|} \]

The term frequency factor counts the number \textit{n} of the \textit{i}\textsubscript{th} term inside the \textit{j}\textsubscript{th} document (the tweet, in our case), dividing it by the lenght of the latest, in order to give same importance to both short and long collections of texts.

\[ IDF_{i} =\log {\frac {|D|}{|\{d:i\in d\}| + 1}} \]
Where \textit{d} is the document (tweet).

The inverse document frequency factor aims to highlight the overall magnitude of the  i\textsubscript{th} term in the collection  which it belongs. The collection \textit{D}, in our work, is represented by all the gathered tweets of the examined user.
\[(TF-IDF)_{i} = TF_{i,j} \times IDF_{i} \]

After the encoding process, we wanted to map the resulting vectors into an euclidean space, in order to compute the distance of each weighted text, from the total centroid of the collection.

We decided to add each user a measure of the average intra-distance of its tweets.\\
In order to achieve this goal, we relied on the WSS metric used in K-means clustering, but trying to soften its magnitude. We didn't want huge ranges in our features, in order to minimize the normalizations along the process.

The resulting formula for this brand new attribute is the following:
\[IntraDistance(U) = \frac{1}{N}\sum _{\mathbf {x} \in U}\left\|\mathbf {x} -{\boldsymbol {\mu }}\right\|^{2}\]
Where \textit{N} is the number of tweet for user \textit{U}, \textit{x} is the encoded tweet and $\mu$ is the centroid of the tweet collection for that user.

This formula, as well as the whole process, has been used both for tweet words and URLs inside of them.
The resulting 2 features are
\small
\begin{center}
	\begin{tabular}{ll}
		\\feature&type\\
		\hline\hline
		tweet\_intradistance&float\\
		url\_intradistance&float\\\hline\\
	\end{tabular}
\end{center}
\normalsize
We expected low values for Spam-bot accounts in both features, as well as we expected the opposite for Genuine and Fake-Follower accounts.


\section{Extrinsic features}
Once we have modelled the personal twitting actions, in terms of words and links dissimilarity, we needed to look for those parameters that could be compared with all the users in our dataset.
We wanted the users to get out of their shells, and to match their timelines with each others.

Once again, sentiment analysis came to our mind. We found lots of paid or limited services that could have only partially supported us during this stage.\\
We couldn't think about implementing our own semantic analysis, as it is meant to be, due to the effort and time it would had taken.\\
For simplicity sake, we had the idea to look for the most meaningful words in tweets, that are common to all the users belonging to the same class.\\
We tried this approach, hoping to find a robust help in separating topics among targets.

The idea was to build five partially-non-overlapping dictionaries, one for each class of users, containing the most popular words used by them in their retrieved tweets, stripped of stopwords. Each dictionary is ordered according to the occurrence of each word, in order to have a proper ranking for the terms and to give each of them a score.

We gathered the 300 most common words for each category of accounts, in order to average about 250 terms, once the overlapping elements would have been discarded.
Considering more than 300 words led us to irrelevant performance boost, instead it required lot of time to process a single user, so we decided to stop early.

We have listed 5 dictionaries: 
\small
\begin{center}
	\begin{tabular}{ll}
		\\dictionary&size\\
		\hline\hline
		NSFW\_main\_words.csv&209\\
		spam\_bots\_main\_words.csv&230\\
		news\_spreders\_main\_words.csv&237\\
		fake\_followers\_main\_words.csv&233\\
		genuine\_main\_words.csv&223\\\hline\\
	\end{tabular}
\end{center}
\normalsize

The overall scores are normalized, so that the most common word, for each class, is associated with a unitary weight, the least common one with a value similar to zero (it depends on the final amount of words included in the dictionary).

In terms of representation, this \textit{keywords score} is built with 5 different values, one for each class.\\
The dictionaries aren't totally disjointed with each others.
We decided to strip, from each list, only the top 50 words belonging to the other collections, since the most relevant scores reside in that zone of the ranking. We didn't want to give the user high scores, for the same word, but in different categories.

If some user hit a word that is placed inside more than a dictionary, we wanted to let the relative weights speak and assign scores to each of the targets that contain that word, knowing they are less relevant, as they don't fall in the highest positions.\\
So we have

\small
\begin{center}
	\begin{tabular}{ll}
		\\feature&type\\
		\hline\hline
		NSFW\_words\_score&float\\
		spam\_bots\_words\_score&float\\
		news\_spreders\_words\_score&float\\
		fake\_followers\_words\_score&float\\
		genuine\_words\_score&float\\\hline\\
	\end{tabular}
\end{center}
\normalsize
When we process a new user and infer on him, we scan every words of every tweets and match them with all the dictionary. Every time that we hit a listed word, we assign the user the score of that word.

For instance, If the word we are comparing matches with the most frequent for NSFW accounts (the top position in its dictionary), we update the \textit{NSFW\_words\_score} of our user, summing 1 to its current value for that feature.

We expected to capture patterns about the choice of the words involved in tweets, for each of our categories.
This extrinsic attributes revealed themselves as very useful, lately.


\section{Image features}
One of the main issues of our work was to make the NSFW class different, in terms of classifiers vision, with respect of Spam-bots.

According to our user-based, descriptive and intrinsic features, both classes act in a similar way: they spam similar links, have high tweet frequency and their contents are often repeated.\\
What could be the difference?

We started with "blind" classifier, that was the main problem. Our feature vector lacked in visual components. A Spam-bot could have been detected as a NSFW, as its tweets involved media and URLs. We needed to go deep and actually see what kind of media were broadcast.\\
This is the reason for presence of the upcoming features.

We've found a small versatile project on GitHub for NSFW detection.\\
The projects involves a pre-trained TensorFlow neural network for image recognition, that looks for adult and violent content inside pictures. It assigns the media a probability to be not safe for work.

We decided to scan our dataset with this new component and to give a NSFW score to both profile pictures and tweets.\\
For time complexity reasons, we couldn't imagine to scan all the retrieved tweets for each user and to look for embedded media. We limited the process to the latest ten tweets.\\

Obviously, the prediction time has been affected by this new preprocessing stage, but we think that this number of pictures analysed (up to eleven), makes the generalization duration still reasonable.\\
The project creators claim to reach 98.2\% of accuracy in their final test, so we thought that the bias introduced with this new features would have been under control and that it wouldn't compromise the final results of our models.

The brand new attributes that helped us in better sperating NSFW class are:
\small
\begin{center}
	\begin{tabular}{ll}
		\\feature&type\\
		\hline\hline
		NSFW\_profile&float\\
		NSFW\_avg&float\\\hline
	\end{tabular}
\end{center}
\normalsize

\section{final feature vector}
\label{sec:feature_vector}
At the end of this process we obtained a feature vector composed of 38 elements, 12 based on the user and 26 based on his tweets.

\subsection{User features}


\small
\begin{center}
	\begin{tabular}{lll}
		\textbf{Features}\\
		\hline\hline
		age\\
		default\_profile\\
		description\_len\\
		favourites\_count\\
		friends\_count\\
		followers\_count\\
		listed\_count\\
		profile\_use\_background\_image\\
		name\_len\\
		screen\_name\_len\\
		statuses\_count\\
		url\\
		\hline
		
	\end{tabular}
\end{center}
\normalsize

\subsection{Tweets features}
\small
\begin{center}
	\begin{tabular}{lll}
		\textbf{Descriptive features}\\
		\hline\hline
		freq\\
		min\_fav\\
		avg\_fav\\
		max\_fav\\
		min\_hash\\
		avg\_hash\\
		max\_hash\\
		min\_len\\
		avg\_len\\
		max\_len\\
		min\_ret\\
		avg\_ret\\
		max\_ret\\
		media\_perc\\
		quote\_perc\\
		ret\_perc\\
		url\_perc\\\hline
	\end{tabular}
\end{center}
\newpage
\begin{center}
	\begin{tabular}{lll}
		\textbf{Intrinsic features}\\
		\hline\hline
		tweets\_intradistance\\
		url\_intradistance\\\hline\\\\
	\end{tabular}
\end{center}


\begin{center}
	\begin{tabular}{lll}
		\textbf{Extrinsic features}\\
		\hline\hline
		NSFW\_words\_score\\
		news\_spreaders\_words\_score\\
		spam\_bots\_words\_score\\
		fake\_followers\_words\_score\\
		genuine\_words\_score\\
		\hline\\\\
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{lll}
		\textbf{Images features}\\
		\hline\hline
		NSFW\_profile\\
		NSFW\_avg\\\hline
	\end{tabular}
\end{center}

\normalsize


