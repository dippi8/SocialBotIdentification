{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets:\n",
    "#    0: porn\n",
    "#    1: propaganda\n",
    "#    2: spam\n",
    "#    3: fake followers\n",
    "#    4: genuine accounts\n",
    "\n",
    "porn_users = pd.read_csv('data/porn/users.csv', encoding='utf-8-sig')\n",
    "prop_users = pd.read_csv('data/propaganda/users.csv', encoding='utf-8-sig')\n",
    "spam_users = pd.read_csv('data/spam/users.csv', encoding='utf-8-sig')\n",
    "fake_users = pd.read_csv('data/fake_followers/users.csv', encoding='utf-8-sig')\n",
    "genuine_users = pd.read_csv('data/genuine/users.csv', encoding='utf-8-sig')\n",
    "\n",
    "porn_ids = porn_users['id']\n",
    "prop_ids = prop_users['id']\n",
    "spam_ids = spam_users['id']\n",
    "fake_ids = fake_users['id']\n",
    "gen_ids = genuine_users['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid(tf_idf):\n",
    "\n",
    "    center = tf_idf.sum(axis=1)/tf_idf.shape[0]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_from_centroid(tf_idf, centroid):\n",
    "    \n",
    "    distances = []\n",
    "    for elem in tf_idf:\n",
    "        distances.append(np.linalg.norm(tf_idf - centroid))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wss(id, tweets_df, is_tweet = 1):\n",
    "    \n",
    "    if is_tweet == 1:\n",
    "        # get tweets per id\n",
    "        vector = tweets_df[tweets_df.user_id == id]['full_text']\n",
    "        n_vectors = len(vector)\n",
    "    elif is_tweet == 0:\n",
    "        # get domains per id\n",
    "        vector = urlparse(tweets_df[tweets_df.user_id == id]['url'])\n",
    "        n_vectors = len(vector)\n",
    "    else:\n",
    "        print ('Invalid Input')\n",
    "\n",
    "    \n",
    "    transformer = TfidfVectorizer(smooth_idf=True)\n",
    "    tf_idf = transformer.fit_transform(vector).todense()\n",
    "    \n",
    "    centroid = compute_centroid(tf_idf)\n",
    "    distances = dist_from_centroid(tf_idf, centroid)\n",
    "    avg_dist = np.asarray(distances).sum()/n_vectors\n",
    "    \n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intradistance(bot_ids, bot_type, is_tweet=1):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "    \n",
    "    distances = []\n",
    "    i=0\n",
    "    for user in bot_ids:\n",
    "        i += 1\n",
    "        try:\n",
    "            distances.append(wss(user, tweets_df, is_tweet))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            distances.append(0)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "    \n",
    "    dist = pd.DataFrame()\n",
    "    dist['user_id'] = bot_ids.values\n",
    "    if is_tweet == 1:\n",
    "        dist['tweet_intradistance'] = distances\n",
    "        dist.to_csv('data/' + bot_type + '/tweet_intradistance.csv')\n",
    "    elif is_tweet == 0:\n",
    "        dist['url_intradistance'] = distances\n",
    "        dist.to_csv('data/' + bot_type + '/url_intradistance.csv')\n",
    "    else:\n",
    "        print ('Invalid Input')\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6910 porn bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "porn done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(porn_ids, 'porn', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(porn_ids, 'porn', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4940 spam bots processed\n",
      "spam done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(spam_ids, 'spam', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(spam_ids, 'spam', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8820 fake_followers bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(fake_ids, 'fake_followers', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(fake_ids, 'fake_followers', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(prop_ids, 'propaganda', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(prop_ids, 'propaganda', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(prop_ids, 'genuine', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(prop_ids, 'genuine', is_tweet=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,9,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (1,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,9,12,19,20,21,24,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "porn_tweets_df = pd.read_csv('data/porn/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "prop_tweets_df = pd.read_csv('data/propaganda/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "spam_tweets_df = pd.read_csv('data/spam/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "fake_tweets_df = pd.read_csv('data/fake_followers/tweets.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def get_main_words(tweets_df):\n",
    "    \n",
    "    n_words = 300\n",
    "    tweets = tweets_df['full_text'].values.astype('str')\n",
    "    \n",
    "    #tokenize and remove stop words \n",
    "    punctuation = list(string.punctuation)\n",
    "    stopWords = stopwords.words('english') + stopwords.words('italian') + stopwords.words('french') + stopwords.words('spanish') + punctuation + ['...', '\"the', \"i'm\", 'go', 'time', 'get', 'rt', 'via', '&amp;'] + [\"it's\"]\n",
    "\n",
    "    word_counter = Counter()\n",
    "    for elem in tweets:\n",
    "        word_counter.update(elem.lower().split())\n",
    "    \n",
    "    for word in stopWords:\n",
    "        if word in word_counter:\n",
    "            del word_counter[word]\n",
    "            \n",
    "\n",
    "    main_words = pd.DataFrame(data=word_counter.most_common(n_words), index=None, columns=['word', 'score'])\n",
    "    \n",
    "    return main_words[:n_words-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vocabularies():\n",
    "    porn_voc = pd.read_csv('data/porn/main_words.csv', sep=',')\n",
    "    prop_voc = pd.read_csv('data/propaganda/main_words.csv', sep=',')\n",
    "    spam_voc = pd.read_csv('data/spam/main_words.csv', sep=',')\n",
    "    fake_voc = pd.read_csv('data/fake_followers/main_words.csv', sep=',')\n",
    "    \n",
    "    porn_words = set(porn_voc['word'])\n",
    "    porn_main_words = set(porn_voc['word'][:50])\n",
    "    prop_words = set(prop_voc['word'])\n",
    "    prop_main_words = set(prop_voc['word'][:50])\n",
    "    spam_words = set(spam_voc['word'])\n",
    "    spam_main_words = set(spam_voc['word'][:50])\n",
    "    fake_words = set(fake_voc['word'])\n",
    "    fake_main_words = set(fake_voc['word'][:50])\n",
    "    \n",
    "    new_porn_words = porn_words - set(prop_main_words | spam_main_words | fake_main_words)\n",
    "    new_prop_words = prop_words - set(porn_main_words | spam_main_words | fake_main_words)\n",
    "    new_spam_words = spam_words - set(prop_main_words | porn_main_words | fake_main_words)\n",
    "    new_fake_words = fake_words - set(prop_main_words | spam_main_words | porn_main_words)\n",
    "    \n",
    "    print(str(len(new_porn_words)) + ' porn words')\n",
    "    print(str(len(new_prop_words)) + ' prop words')\n",
    "    print(str(len(new_spam_words)) + ' spam words')\n",
    "    print(str(len(new_fake_words)) + ' fake words')\n",
    "    \n",
    "    # normalize scores\n",
    "    porn_voc = porn_voc[porn_voc['word'].isin(list(new_porn_words))]\n",
    "    scaler = MinMaxScaler() \n",
    "    porn_voc['score'] = scaler.fit_transform(porn_voc.score.values.reshape(-1, 1))\n",
    "    porn_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    porn_voc.drop(porn_voc.tail(1).index, inplace=True)\n",
    "    porn_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    prop_voc = prop_voc[prop_voc['word'].isin(list(new_prop_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    prop_voc['score'] = scaler.fit_transform(prop_voc.score.values.reshape(-1, 1))\n",
    "    prop_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    prop_voc.drop(prop_voc.tail(1).index, inplace=True)\n",
    "    prop_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spam_voc = spam_voc[spam_voc['word'].isin(list(new_spam_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    spam_voc['score'] = scaler.fit_transform(spam_voc.score.values.reshape(-1, 1))\n",
    "    spam_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    spam_voc.drop(spam_voc.tail(1).index, inplace=True)\n",
    "    spam_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    fake_voc = fake_voc[fake_voc['word'].isin(list(new_fake_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    fake_voc['score'] = scaler.fit_transform(fake_voc.score.values.reshape(-1, 1))\n",
    "    fake_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    fake_voc.drop(fake_voc.tail(1).index, inplace=True)\n",
    "    fake_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    porn_voc.to_csv('data/porn/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    prop_voc.to_csv('data/propaganda/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    spam_voc.to_csv('data/spam/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    fake_voc.to_csv('data/fake_followers/filtered_main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_vocabulary = get_main_words(porn_tweets_df)\n",
    "porn_vocabulary.to_csv('data/porn/main_words.csv', encoding='utf-8-sig')\n",
    "prop_vocabulary = get_main_words(prop_tweets_df)\n",
    "prop_vocabulary.to_csv('data/propaganda/main_words.csv', encoding='utf-8-sig')\n",
    "spam_vocabulary = get_main_words(spam_tweets_df)\n",
    "spam_vocabulary.to_csv('data/spam/main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vocabulary = get_main_words(fake_tweets_df)\n",
    "fake_vocabulary.to_csv('data/fake_followers/main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 porn words\n",
      "248 prop words\n",
      "244 spam words\n",
      "239 fake words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "unique_vocabularies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_words = pd.read_csv('data/porn/filtered_main_words.csv', sep=',')\n",
    "prop_words = pd.read_csv('data/propaganda/filtered_main_words.csv', sep=',')\n",
    "spam_words = pd.read_csv('data/spam/filtered_main_words.csv', sep=',')\n",
    "fake_words = pd.read_csv('data/fake_followers/filtered_main_words.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(tweets):\n",
    "\n",
    "    user_score = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # check for words in main_words and compute the scores for each tweet and for each category\n",
    "        mask = np.in1d(porn_words.word, tweet.split())\n",
    "        porn_score = porn_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(prop_words.word, tweet.split())\n",
    "        prop_score = prop_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(spam_words.word, tweet.split())\n",
    "        spam_score = spam_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(fake_words.word, tweet.split())\n",
    "        fake_score = fake_words.loc[mask]['score'].values.sum()\n",
    "        \n",
    "        user_score = user_score.append(pd.DataFrame({'porn_words_score': porn_score, 'prop_words_score': prop_score, 'spam_words_score': spam_score,'fake_words_score': fake_score}, index=[0]), ignore_index=True)\n",
    "\n",
    "    return user_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(tweets_df, id):\n",
    "    \n",
    "    tweets = tweets_df[tweets_df.user_id == id]['full_text']\n",
    "    if len(tweets) > 0:\n",
    "        # sum all the scores of each category\n",
    "        user_score = compute_score(tweets).sum()\n",
    "        scores = np.divide(user_score,len(tweets))\n",
    "    else:\n",
    "        scores = pd.DataFrame({'porn_words_score': 0, 'prop_words_score': 0, 'spam_words_score': 0,'fake_words_score': 0}, index=[0])\n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_score(bot_ids, bot_type):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "        \n",
    "    score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'user_id'])\n",
    "    i = 0\n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        scores = score(tweets_df, user_id)\n",
    "        scores['user_id'] = user_id\n",
    "        score_df = score_df.append(scores, ignore_index=True)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "            \n",
    "    score_df.reset_index(drop=True, inplace=True)\n",
    "    score_df.to_csv('data/' + bot_type + '/context_score.csv')\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6910 porn bots processed\n",
      "porn done!\n"
     ]
    }
   ],
   "source": [
    "context_score(porn_ids, 'porn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "context_score(prop_ids, 'propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4940 spam bots processed\n",
      "spam done!\n"
     ]
    }
   ],
   "source": [
    "context_score(spam_ids, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8820 fake_followers bots processed\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "context_score(fake_ids, 'fake_followers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tweets(tweets):\n",
    "    \n",
    "    ret_perc, media_perc, url_perc, quote_perc = tweet_perc(tweets)\n",
    "    \n",
    "    avg_len, avg_ret, avg_fav = tweet_desc(tweets, 'avg')\n",
    "    max_len, max_ret, max_fav = tweet_desc(tweets, 'max')\n",
    "    min_len, min_ret, min_fav = tweet_desc(tweets, 'min')\n",
    "    \n",
    "    freq = tweet_freq(tweets)\n",
    "\n",
    "    frame = np.array([avg_len, max_len, min_len, avg_ret, max_ret, min_ret, avg_fav, max_fav, min_fav, freq, ret_perc, media_perc, url_perc, quote_perc])\n",
    "\n",
    "    \n",
    "    desc_features = pd.DataFrame({'avg_len': avg_len, 'max_len': max_len, 'min_len': min_len, 'avg_ret': avg_ret, 'max_ret': max_ret, 'min_ret': min_ret, 'avg_fav': avg_fav, 'max_fav': max_fav, 'min_fav': min_fav, 'freq': freq, 'ret_perc': ret_perc, 'media_perc': media_perc, 'url_perc': url_perc, 'quote_perc': quote_perc}, index=[0])\n",
    "    \n",
    "    \n",
    "    return desc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_perc(tweets):\n",
    "    \n",
    "    ret_perc = np.invert(tweets.retweeted_status.isnull()).sum()/len(tweets)\n",
    "    media_perc = np.invert(tweets.extended_entities.isnull()).sum()/len(tweets)\n",
    "    url_perc = np.invert(tweets.url.isnull()).sum()/len(tweets)\n",
    "    quote_perc = tweets.is_quote_status.sum()/len(tweets)\n",
    "    \n",
    "    return ret_perc, media_perc, url_perc, quote_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_desc(tweets, metric):\n",
    "    \n",
    "    tweets_lenght = tweets['full_text'].apply(lambda x: len(x))\n",
    "    \n",
    "    if metric == 'avg':\n",
    "        ret = np.mean(tweets.retweet_count)\n",
    "        lenght = np.mean(tweets_lenght)\n",
    "        fav = np.mean(tweets.favorite_count)\n",
    "    elif metric == 'max':\n",
    "        ret = max(tweets.retweet_count)\n",
    "        lenght = max(tweets_lenght)\n",
    "        fav = max(tweets.favorite_count)\n",
    "    elif metric == 'min':\n",
    "        ret = min(tweets.retweet_count)\n",
    "        lenght = min(tweets_lenght)\n",
    "        fav = min(tweets.favorite_count)\n",
    "\n",
    "    return lenght, ret, fav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_freq(tweets):\n",
    "    \n",
    "    dates = list(tweets.created_at)\n",
    "    \n",
    "    last = dates[0]\n",
    "    d = last[8:10]\n",
    "    m = last[4:7]\n",
    "    y = last[-4:]\n",
    "    date = d + ' ' + m + ' ' + y\n",
    "    last = datetime.strptime(date, '%d %b %Y')\n",
    "    \n",
    "    first = dates[-1]\n",
    "    d = first[8:10]\n",
    "    m = first[4:7]\n",
    "    y = first[-4:]\n",
    "    date = d + ' ' + m + ' ' + y\n",
    "    first = datetime.strptime(date, '%d %b %Y')\n",
    "    \n",
    "    delta = (last - first).days + 1\n",
    "    freq = len(tweets)/delta\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(tweets_df, id):\n",
    "    \n",
    "    tweets = tweets_df[tweets_df.user_id == id]\n",
    "    \n",
    "    if len(tweets) > 0:\n",
    "        # sum all the scores of each category\n",
    "        features = describe_tweets(tweets)\n",
    "    else:\n",
    "        features = pd.DataFrame({'avg_len': 0, 'max_len': 0, 'min_len': 0,'avg_ret': 0, 'max_ret': 0, 'min_ret': 0, 'avg_fav': 0, 'max_fav': 0, 'min_fav': 0, 'freq': 0, 'ret_perc': 0, 'media_perc': 0, 'url_perc': 0, 'quote_perc':0}, index=[0])\n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_features(bot_ids, bot_type):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "        \n",
    "    desc_df = pd.DataFrame(columns=['avg_len', 'max_len', 'min_len', 'avg_ret', 'max_ret', 'min_ret', 'avg_fav', 'max_fav', 'min_fav', 'freq', 'ret_perc', 'media_perc', 'url_perc', 'quote_perc'])\n",
    "    i = 0\n",
    "    \n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        features = describe(tweets_df, user_id)\n",
    "        features['user_id'] = user_id\n",
    "        desc_df = desc_df.append(features, ignore_index=True)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "            \n",
    "    desc_df.reset_index(drop=True, inplace=True)\n",
    "    desc_df.to_csv('data/' + bot_type + '/descriptive_features.csv')\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2808: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'retweeted_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-203b408e63e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdescriptive_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fake_followers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-664bb27600e6>\u001b[0m in \u001b[0;36mdescriptive_features\u001b[0;34m(bot_ids, bot_type)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbot_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdesc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-eff15c69ad2b>\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(tweets_df, id)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# sum all the scores of each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'avg_len'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_len'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_len'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avg_ret'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_ret'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_ret'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'freq'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ret_perc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'media_perc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'url_perc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-01ab5516d906>\u001b[0m in \u001b[0;36mdescribe_tweets\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdescribe_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mret_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_perc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mavg_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-186f4d8bb1b8>\u001b[0m in \u001b[0;36mtweet_perc\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtweet_perc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mret_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretweeted_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmedia_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_entities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0murl_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'retweeted_status'"
     ]
    }
   ],
   "source": [
    "descriptive_features(fake_ids, 'fake_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = pd.read_csv('data/propaganda/descriptive_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_len</th>\n",
       "      <th>avg_ret</th>\n",
       "      <th>freq</th>\n",
       "      <th>max_len</th>\n",
       "      <th>max_ret</th>\n",
       "      <th>media_perc</th>\n",
       "      <th>min_len</th>\n",
       "      <th>min_ret</th>\n",
       "      <th>ret_perc</th>\n",
       "      <th>url_perc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3.301000e+03</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3301.000000</td>\n",
       "      <td>3.301000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.399118</td>\n",
       "      <td>3087.114962</td>\n",
       "      <td>36.373379</td>\n",
       "      <td>189.455922</td>\n",
       "      <td>3.996550e+04</td>\n",
       "      <td>0.103343</td>\n",
       "      <td>39.523478</td>\n",
       "      <td>10.879128</td>\n",
       "      <td>0.862170</td>\n",
       "      <td>0.233608</td>\n",
       "      <td>3.267065e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.377480</td>\n",
       "      <td>3738.590667</td>\n",
       "      <td>29.886725</td>\n",
       "      <td>89.970273</td>\n",
       "      <td>9.109144e+04</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>14.340845</td>\n",
       "      <td>150.004112</td>\n",
       "      <td>0.265045</td>\n",
       "      <td>0.203501</td>\n",
       "      <td>4.099872e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012635</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.551130e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>122.150000</td>\n",
       "      <td>1059.800000</td>\n",
       "      <td>12.375000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.806900e+04</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.126252e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>127.560000</td>\n",
       "      <td>2193.050505</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>2.975100e+04</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>3.035315e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>131.570000</td>\n",
       "      <td>4042.330000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>3.542100e+04</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.003112e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>373.390000</td>\n",
       "      <td>113761.066667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>3.369452e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>6053.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.852123e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           avg_len        avg_ret         freq      max_len       max_ret  \\\n",
       "count  3301.000000    3301.000000  3301.000000  3301.000000  3.301000e+03   \n",
       "mean    126.399118    3087.114962    36.373379   189.455922  3.996550e+04   \n",
       "std      17.377480    3738.590667    29.886725    89.970273  9.109144e+04   \n",
       "min      23.000000       0.000000     0.012635    23.000000  0.000000e+00   \n",
       "25%     122.150000    1059.800000    12.375000   144.000000  1.806900e+04   \n",
       "50%     127.560000    2193.050505    33.333333   148.000000  2.975100e+04   \n",
       "75%     131.570000    4042.330000    50.000000   209.000000  3.542100e+04   \n",
       "max     373.390000  113761.066667   100.000000   977.000000  3.369452e+06   \n",
       "\n",
       "        media_perc      min_len      min_ret     ret_perc     url_perc  \\\n",
       "count  3301.000000  3301.000000  3301.000000  3301.000000  3301.000000   \n",
       "mean      0.103343    39.523478    10.879128     0.862170     0.233608   \n",
       "std       0.115992    14.340845   150.004112     0.265045     0.203501   \n",
       "min       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.040000    30.000000     0.000000     0.890000     0.120000   \n",
       "50%       0.080000    40.000000     0.000000     0.989899     0.171717   \n",
       "75%       0.130000    46.000000     1.000000     1.000000     0.250000   \n",
       "max       1.000000   235.000000  6053.000000     1.000000     1.000000   \n",
       "\n",
       "            user_id  \n",
       "count  3.301000e+03  \n",
       "mean   3.267065e+17  \n",
       "std    4.099872e+17  \n",
       "min    7.551130e+05  \n",
       "25%    5.126252e+08  \n",
       "50%    3.035315e+09  \n",
       "75%    8.003112e+17  \n",
       "max    9.852123e+17  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_len</th>\n",
       "      <th>avg_ret</th>\n",
       "      <th>freq</th>\n",
       "      <th>max_len</th>\n",
       "      <th>max_ret</th>\n",
       "      <th>media_perc</th>\n",
       "      <th>min_len</th>\n",
       "      <th>min_ret</th>\n",
       "      <th>ret_perc</th>\n",
       "      <th>url_perc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.01000</td>\n",
       "      <td>1268.85000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>147</td>\n",
       "      <td>17340</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.010638e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126.93000</td>\n",
       "      <td>2402.32000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>307</td>\n",
       "      <td>36501</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>7.204254e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161.79000</td>\n",
       "      <td>1703.37000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>316</td>\n",
       "      <td>28404</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>9.228370e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124.84000</td>\n",
       "      <td>201.85000</td>\n",
       "      <td>50.00</td>\n",
       "      <td>144</td>\n",
       "      <td>4185</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>8.182995e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.89899</td>\n",
       "      <td>2675.30303</td>\n",
       "      <td>8.25</td>\n",
       "      <td>185</td>\n",
       "      <td>29984</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>8.377794e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_len     avg_ret    freq  max_len  max_ret  media_perc  min_len  \\\n",
       "0  135.01000  1268.85000   50.00      147    17340    0.050000       61   \n",
       "1  126.93000  2402.32000  100.00      307    36501    0.060000       42   \n",
       "2  161.79000  1703.37000   10.00      316    28404    0.050000       30   \n",
       "3  124.84000   201.85000   50.00      144     4185    0.090000       51   \n",
       "4  120.89899  2675.30303    8.25      185    29984    0.090909       23   \n",
       "\n",
       "   min_ret  ret_perc  url_perc       user_id  \n",
       "0        1  1.000000  0.130000  8.010638e+17  \n",
       "1        0  0.920000  0.150000  7.204254e+17  \n",
       "2        0  0.470000  0.570000  9.228370e+17  \n",
       "3        0  0.990000  0.110000  8.182995e+17  \n",
       "4        0  0.757576  0.080808  8.377794e+17  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2,9,12,19,20,21,24,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/spam/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                   0\n",
       "contributors                                                               NaN\n",
       "coordinates                                                                NaN\n",
       "created_at                                      Fri Dec 05 02:19:38 +0000 2014\n",
       "display_text_range                                                     [0, 55]\n",
       "extended_entities                                                          NaN\n",
       "favorite_count                                                               2\n",
       "favorited                                                                False\n",
       "full_text                    Read the History of David Gates  http://t.co/Y...\n",
       "geo                                                                        NaN\n",
       "id                                                          540691938639630336\n",
       "id_str                                                      540691938639630336\n",
       "in_reply_to_screen_name                                                    NaN\n",
       "in_reply_to_status_id                                                      NaN\n",
       "in_reply_to_status_id_str                                                  NaN\n",
       "in_reply_to_user_id                                                        NaN\n",
       "in_reply_to_user_id_str                                                    NaN\n",
       "is_quote_status                                                          False\n",
       "lang                                                                        en\n",
       "place                                                                      NaN\n",
       "possibly_sensitive                                                       False\n",
       "quoted_status                                                              NaN\n",
       "quoted_status_id                                                           NaN\n",
       "quoted_status_id_str                                                       NaN\n",
       "quoted_status_permalink                                                    NaN\n",
       "retweet_count                                                                2\n",
       "retweeted                                                                False\n",
       "retweeted_status                                                           NaN\n",
       "source                       <a href=\"http://tweetadder.com\" rel=\"nofollow\"...\n",
       "truncated                                                                False\n",
       "url                          http://oldiesmusic.hubpages.com/hub/History-of...\n",
       "user_id                                                              347491211\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
