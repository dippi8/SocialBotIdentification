{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('data/full/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[['user_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.concat([pd.read_csv('data/porn/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/propaganda/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/spam/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/fake_followers/tweets.csv', sep='\\t')[['user_id','full_text']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(tweets, users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['user_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets[tweets.target==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://t.co/KiTk9FMJwj'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[2].full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196811    RT @funder: Retweetfest: Tweet this link out i...\n",
       "196812    RT @RWPUSA: So much for party labels. With Dem...\n",
       "196813    RT @funder: BREAKING: Trump just said he’s ref...\n",
       "196814    RT @robreiner: When an American President atta...\n",
       "196815    RT @SteveSchmidtSES: TRUMP disgraced the Presi...\n",
       "196816    RT @funder: BREAKING: Republicans are trying t...\n",
       "196817    RT @GovHowardDean: The Trump administration no...\n",
       "196818    RT @SenFeinstein: BREAKING: I’ve introduced ou...\n",
       "196819    RT @ProudResister: Donald Trump is attacking t...\n",
       "196820    RT @RepSwalwell: Why, @realDonaldTrump? Looks ...\n",
       "196821    RT @SteveSchmidtSES: The American people will ...\n",
       "196822    RT @SteveSchmidtSES: A clear line has been dra...\n",
       "196823    RT @NotDexVonFrisch: From Privilege to Progres...\n",
       "196824    RT @funder: Retweet if you accept Joy Reid’s a...\n",
       "196825    RT @BwanaSokwe: @thehill @realDonaldTrump 's a...\n",
       "196826    RT @politvidchannel: BREAKING: Nine state atto...\n",
       "196827    RT @chrislhayes: The last time America had suc...\n",
       "196828    RT @RepSwalwell: The @realDonaldTrump pardon h...\n",
       "196829    RT @Stricknine116: @tackettdc @maggieNYT Maggi...\n",
       "196830    RT @owillis: obama pardoned people who faced r...\n",
       "196831    RT @Anthony90069: @realDonaldTrump Dinesh D’So...\n",
       "196832    RT @sammypolsen12: @realDonaldTrump Hey! Cohen...\n",
       "196833    RT @mkraju: “I think he’s dead wrong,” John Ka...\n",
       "196834    RT @brycetache: An open letter to all journali...\n",
       "196835    RT @SenFeinstein: It’s hard to conceive of a p...\n",
       "196836    RT @robreiner: Babies taken from their mothers...\n",
       "196837    RT @DearAuntCrabby: Roseanne blaming Ambien fo...\n",
       "196838    RT @funder: For the kid who asked the question...\n",
       "196839    RT @thetruthwillout: Everyone should see this!...\n",
       "196840    RT @KellyO: Giuiliani on AG Jeff Sessions \"The...\n",
       "                                ...                        \n",
       "477081    RT @reclaimchicago: “Mass incarceration is par...\n",
       "477082    RT @_JacobSL: This is a room full of 1,000 peo...\n",
       "477083    Thousands of formerly incarcerated individuals...\n",
       "477084              #ProtestToPower https://t.co/Qgv49GtwxE\n",
       "477085    Healthcare is treated as a commodity, as a sou...\n",
       "477086    The movement needs to take on the fight for ra...\n",
       "477087    Mass incarceration is a part of the system of ...\n",
       "477088    \"An injury to one is an injury to all.\" -Marte...\n",
       "477089    RT @Suntimes: If city, state can pay $2.25B Am...\n",
       "477090    RT @fairtrade_Ervin: RT! Chicagoans need to in...\n",
       "477091    RT @CLAWabolition: Abolition is about building...\n",
       "477092    RT @HeavySan: \"Bye Jamaican Barbie\": Universit...\n",
       "477093    RT @EverythingTaj: \"I can finally say goodbye ...\n",
       "477094    RT @jeligon: \"This new wave of everyone kneeli...\n",
       "477095    RT @JuddLegum: Hannity assembles a diverse pan...\n",
       "477096    City Haul: More than a third of Chicago city w...\n",
       "477097    RT @ISBEnews: \"There is no room for racism, ha...\n",
       "477098    RT @nytimes: Breaking News: The \"evil attack\" ...\n",
       "477099    RT @imaniperry: Americans are so habituated to...\n",
       "477100    RT @Princeton: A record-setting $74.9 million ...\n",
       "477101    RT @EricHolder: To the career men &amp; women ...\n",
       "477102    RT @deray: 1,155 people killed by police in 20...\n",
       "477103    @SouthwestAir It is now more than 24 hours sin...\n",
       "477104    @SouthwestAir what's going on? Will I ever mak...\n",
       "477105    @SouthwestAir both of my flights from Chicago ...\n",
       "477106    RT @AP: BREAKING: Republican Greg Gianforte wi...\n",
       "477107    RT @PreetBharara: Repost in honor of alleged c...\n",
       "477108    Federal Bureau Of Prisons Fires Head Of An Oba...\n",
       "477109    RT @RheaButcher: Since we're taking down Confe...\n",
       "477110    RT @Trevornoah: Did you know that If you tell ...\n",
       "Name: full_text, Length: 280300, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets.target == 1].full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rt(x):\n",
    "    if 'RT @' in x:\n",
    "        try:\n",
    "            return x[x.find(':')+2:]\n",
    "        except:\n",
    "            return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def translate(x):\n",
    "#    try:\n",
    "#        return translator.translate(x).text\n",
    "#    except:\n",
    "#        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop(x):\n",
    "    return [word for word in x.split() if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].apply(lambda x: remove_rt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].apply(lambda x: re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].apply(lambda x: re.sub(r'[^\\w\\s]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].apply(lambda x: remove_stop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['full_text'] = tweets['full_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets.full_text!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113472201</td>\n",
       "      <td>['1d', 'stans', 'acting', 'like', '1d', 'super...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1113472201</td>\n",
       "      <td>['hi', 'lets', 'talk', 'look', 'bio']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1113472201</td>\n",
       "      <td>['usernames', 'girls', 'live', 'webcam', 'teen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1113472201</td>\n",
       "      <td>['got', 'tattoo', 'last', 'weekend', 'really',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['worst', 'year', 'entire', 'life', 'officiall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['destined', 'meet', 'meeting', 'sure', 'matte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['hi', 'today', 'great', 'day', 'look', 'bio',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['whos', 'chopper', 'know', 'bangladesh', 'men...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['president', 'thomas', 'monson', '16th', 'pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['mr', 'barbaro', 'nytimes', 'ne', 'foolish', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['newsfix', 'mikiebarb', 'thats', 'get', 'mine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['oh', 'boy', 'thats', 'moi', 'frozeneastriver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['coinbasesupport', 'terrible', 'getting', 'st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['kpmgs', 'david', 'ferbrache', 'thoughts', 't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['knew', 'heard', '1st', 'snoke', 'porg', 'sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['lo', 'que', 'callamos', 'los', 'youtubers', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['shes', 'stealthvintage', 'fat', 'boy', 'lo',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['thing', 'happened', 'delta', 'flight', 'shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['greatest', 'sloth', 'video', 'possibly', 'se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['estimada', 'sandy', 'es', 'un', 'gusto', 'sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['los', 'invito', 'seguir', 'la', 'entrevista'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['acercarme', 'la', 'gente', 'escucharlos', 'a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['envivo', 'conoce', 'a_ahued', 'precandidato'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['envivo', 'aspirantes', 'la', 'cdmx', 'entrev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['el', 'gobierno', 'puede', 'hacer', 'todo', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['envivo', 'puedo', 'decir', 'que', 'desde', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['envivo', 'desde', 'el_universal_mx', 'sigan'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['estamos', 'en', 'un', 'proceso', 'de', 'prec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['hay', 'gente', 'que', 'deja', 'de', 'hablar'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>29795845</td>\n",
       "      <td>['tune', 'every', 'friday', 'sat', 'nigezietv'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233250</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['cant', 'believe', 'already', 'august', 'sure...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233251</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['congratulations', 'thomas', 'taylor', 'msd',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233252</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['wishing', 'president', 'lance', 'swank', 'ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233253</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['moving', 'unfamiliar', 'place', 'summer', 'm...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233254</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['employees', 'opinions', 'help', 'us', 'provi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233255</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['crystal', 'branstiters', 'portfolio', '13', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233256</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['sterling', 'group', 'continues', 'grow', 'tw...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233257</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['would', 'like', 'introduce', 'newest', 'memb...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233258</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['keep', 'great', 'work', 'wellsleyparkapt', '...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233259</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['junes', 'silver', 'star', 'award', 'goes', '...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233260</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['cant', 'believe', '258', 'days', 'next', 'st...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233261</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['congratulations', 'nancy', 'salmonson', 'bec...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233262</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['congratulation', 'michelle', 'schillumeit', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233263</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['congrats', 'ronnie', 'robertson', 'hampton',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233264</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['aventine', 'wilderness', 'hills', 'beautiful...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233265</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['wellsleyparkapt', 'maintenance', 'tech', 'jo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233266</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['dave', 'brogdon', 'maintenance', 'supervisor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233267</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['sterling', 'group', 'hiring', 'jobs', 'knoxv...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233268</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['sterling', 'group', 'hiring', 'jobs', 'tulsa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233269</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'yardi', 's...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233270</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'property',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233271</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'project', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233272</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'leasing', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233273</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'leasing', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233274</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'general', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233275</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'general', ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233276</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['garrathi', 'thanks', 'bringing', 'attention'...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233277</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'property',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233278</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'assistant'...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233279</th>\n",
       "      <td>863278244</td>\n",
       "      <td>['retweet', 'help', 'fill', 'job', 'property',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                          full_text  target\n",
       "1        1113472201  ['1d', 'stans', 'acting', 'like', '1d', 'super...       0\n",
       "5        1113472201              ['hi', 'lets', 'talk', 'look', 'bio']       0\n",
       "6        1113472201  ['usernames', 'girls', 'live', 'webcam', 'teen...       0\n",
       "7        1113472201  ['got', 'tattoo', 'last', 'weekend', 'really',...       0\n",
       "8          29795845  ['worst', 'year', 'entire', 'life', 'officiall...       0\n",
       "10         29795845  ['destined', 'meet', 'meeting', 'sure', 'matte...       0\n",
       "13         29795845  ['hi', 'today', 'great', 'day', 'look', 'bio',...       0\n",
       "14         29795845  ['whos', 'chopper', 'know', 'bangladesh', 'men...       0\n",
       "15         29795845  ['president', 'thomas', 'monson', '16th', 'pro...       0\n",
       "16         29795845  ['mr', 'barbaro', 'nytimes', 'ne', 'foolish', ...       0\n",
       "17         29795845  ['newsfix', 'mikiebarb', 'thats', 'get', 'mine...       0\n",
       "18         29795845  ['oh', 'boy', 'thats', 'moi', 'frozeneastriver...       0\n",
       "19         29795845  ['coinbasesupport', 'terrible', 'getting', 'st...       0\n",
       "20         29795845  ['kpmgs', 'david', 'ferbrache', 'thoughts', 't...       0\n",
       "21         29795845  ['knew', 'heard', '1st', 'snoke', 'porg', 'sta...       0\n",
       "22         29795845  ['lo', 'que', 'callamos', 'los', 'youtubers', ...       0\n",
       "23         29795845  ['shes', 'stealthvintage', 'fat', 'boy', 'lo',...       0\n",
       "24         29795845  ['thing', 'happened', 'delta', 'flight', 'shou...       0\n",
       "25         29795845  ['greatest', 'sloth', 'video', 'possibly', 'se...       0\n",
       "26         29795845  ['estimada', 'sandy', 'es', 'un', 'gusto', 'sa...       0\n",
       "27         29795845  ['los', 'invito', 'seguir', 'la', 'entrevista'...       0\n",
       "28         29795845  ['acercarme', 'la', 'gente', 'escucharlos', 'a...       0\n",
       "29         29795845  ['envivo', 'conoce', 'a_ahued', 'precandidato'...       0\n",
       "30         29795845  ['envivo', 'aspirantes', 'la', 'cdmx', 'entrev...       0\n",
       "31         29795845  ['el', 'gobierno', 'puede', 'hacer', 'todo', '...       0\n",
       "32         29795845  ['envivo', 'puedo', 'decir', 'que', 'desde', '...       0\n",
       "33         29795845  ['envivo', 'desde', 'el_universal_mx', 'sigan'...       0\n",
       "34         29795845  ['estamos', 'en', 'un', 'proceso', 'de', 'prec...       0\n",
       "35         29795845  ['hay', 'gente', 'que', 'deja', 'de', 'hablar'...       0\n",
       "36         29795845  ['tune', 'every', 'friday', 'sat', 'nigezietv'...       0\n",
       "...             ...                                                ...     ...\n",
       "1233250   863278244  ['cant', 'believe', 'already', 'august', 'sure...       4\n",
       "1233251   863278244  ['congratulations', 'thomas', 'taylor', 'msd',...       4\n",
       "1233252   863278244  ['wishing', 'president', 'lance', 'swank', 'ha...       4\n",
       "1233253   863278244  ['moving', 'unfamiliar', 'place', 'summer', 'm...       4\n",
       "1233254   863278244  ['employees', 'opinions', 'help', 'us', 'provi...       4\n",
       "1233255   863278244  ['crystal', 'branstiters', 'portfolio', '13', ...       4\n",
       "1233256   863278244  ['sterling', 'group', 'continues', 'grow', 'tw...       4\n",
       "1233257   863278244  ['would', 'like', 'introduce', 'newest', 'memb...       4\n",
       "1233258   863278244  ['keep', 'great', 'work', 'wellsleyparkapt', '...       4\n",
       "1233259   863278244  ['junes', 'silver', 'star', 'award', 'goes', '...       4\n",
       "1233260   863278244  ['cant', 'believe', '258', 'days', 'next', 'st...       4\n",
       "1233261   863278244  ['congratulations', 'nancy', 'salmonson', 'bec...       4\n",
       "1233262   863278244  ['congratulation', 'michelle', 'schillumeit', ...       4\n",
       "1233263   863278244  ['congrats', 'ronnie', 'robertson', 'hampton',...       4\n",
       "1233264   863278244  ['aventine', 'wilderness', 'hills', 'beautiful...       4\n",
       "1233265   863278244  ['wellsleyparkapt', 'maintenance', 'tech', 'jo...       4\n",
       "1233266   863278244  ['dave', 'brogdon', 'maintenance', 'supervisor...       4\n",
       "1233267   863278244  ['sterling', 'group', 'hiring', 'jobs', 'knoxv...       4\n",
       "1233268   863278244  ['sterling', 'group', 'hiring', 'jobs', 'tulsa...       4\n",
       "1233269   863278244  ['retweet', 'help', 'fill', 'job', 'yardi', 's...       4\n",
       "1233270   863278244  ['retweet', 'help', 'fill', 'job', 'property',...       4\n",
       "1233271   863278244  ['retweet', 'help', 'fill', 'job', 'project', ...       4\n",
       "1233272   863278244  ['retweet', 'help', 'fill', 'job', 'leasing', ...       4\n",
       "1233273   863278244  ['retweet', 'help', 'fill', 'job', 'leasing', ...       4\n",
       "1233274   863278244  ['retweet', 'help', 'fill', 'job', 'general', ...       4\n",
       "1233275   863278244  ['retweet', 'help', 'fill', 'job', 'general', ...       4\n",
       "1233276   863278244  ['garrathi', 'thanks', 'bringing', 'attention'...       4\n",
       "1233277   863278244  ['retweet', 'help', 'fill', 'job', 'property',...       4\n",
       "1233278   863278244  ['retweet', 'help', 'fill', 'job', 'assistant'...       4\n",
       "1233279   863278244  ['retweet', 'help', 'fill', 'job', 'property',...       4\n",
       "\n",
       "[1188197 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-684b5d48da62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-684b5d48da62>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0;31m# STEP 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step2_suffixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tional\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc:(stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "stem_vectorizer = StemmedCountVectorizer(stemmer)\n",
    "\n",
    "pipeline = Pipeline([('vect', stem_vectorizer), \n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('mnb', MultinomialNB(fit_prior=False))])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets.full_text, tweets.target, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('accuracy: ' + str(np.mean(y_pred == y_test)))\n",
    "print('partial f1: ' + str(f1_score(y_test, y_pred, average=None)))\n",
    "print('total f1: ' + str(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0646053 , 0.07329557, 0.69675381, 0.01342943, 0.15191589]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(pd.Series(\"Try this awesome app\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.fit(tweets.full_text, tweets.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7668795662672099\n",
      "partial f1: [0.63853231 0.83060419 0.8263119  0.57269671 0.6802656 ]\n",
      "total f1: 0.7096821426189857\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(tweets.full_text)\n",
    "\n",
    "print('accuracy: ' + str(np.mean(y_pred == tweets.target)))\n",
    "print('partial f1: ' + str(f1_score(tweets.target, y_pred, average=None)))\n",
    "print('total f1: ' + str(f1_score(tweets.target, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( clf, open( \"../scripts/nb.model\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
