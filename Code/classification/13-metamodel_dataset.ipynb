{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import tweepy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.read_csv('data/full/rf_preproc_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = rf_df[['user_id', 'avg_fav', 'avg_hash', 'avg_len', 'avg_ret', 'default_profile',\n",
    "       'fake_words_score', 'favourites_count', 'followers_count', 'freq',\n",
    "       'friends_count', 'genuine_words_score', 'listed_count', 'max_fav',\n",
    "       'max_hash', 'max_len', 'max_ret', 'media_perc', 'min_fav', 'min_hash',\n",
    "       'min_len', 'min_ret', 'porn_words_score',\n",
    "       'profile_use_background_image', 'prop_words_score', 'quote_perc',\n",
    "       'ret_perc', 'spam_words_score', 'statuses_count',\n",
    "       'tweet_intradistance', 'url', 'url_intradistance', 'url_perc',\n",
    "       'description_len', 'name_len', 'screen_name_len', 'age','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(rf_df.drop(columns=['target']), rf_df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30, criterion='gini', max_depth=24) #max_depth=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validate(rf, X_train.drop(columns=['user_id']), y_train, cv=10, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582357698077709"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=24, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train.drop(columns=['user_id']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict_proba(X_val.drop(columns=['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93333333, 0.        , 0.        , 0.03333333, 0.03333333]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_val.drop(columns=['user_id']).iloc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4347    610392907\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.iloc[0:1]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prob = pd.DataFrame(rf_pred, columns=['rf_0', 'rf_1', 'rf_2', 'rf_3', 'rf_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prob.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prob['user_id'] = X_val['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prob['target'] = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest df Ã¨ pronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('data/full/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[['user_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,4,8,11,18,19,20,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.concat([pd.read_csv('data/propaganda/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/porn/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/spam/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/fake_followers/tweets.csv', sep='\\t')[['user_id','full_text']], \\\n",
    "          pd.read_csv('data/genuine/tweets.csv', sep='\\t')[['user_id','full_text']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(tweets, users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.in1d(tweets.user_id, X_train.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask = np.in1d(tweets.user_id, X_val.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = tweets[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_val = tweets[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rt(x):\n",
    "    if 'RT @' in x:\n",
    "        try:\n",
    "            return x[x.find(':')+2:]\n",
    "        except:\n",
    "            return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop(x):\n",
    "    return [word for word in x.split() if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nb_train['full_text'] = nb_train['full_text'].apply(lambda x: remove_rt(x))\n",
    "nb_train['full_text'] = nb_train['full_text'].apply(lambda x: re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', x))\n",
    "nb_train['full_text'] = nb_train['full_text'].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "nb_train['full_text'] = nb_train['full_text'].apply(lambda x: x.lower())\n",
    "nb_train['full_text'] = nb_train['full_text'].apply(lambda x: remove_stop(x))\n",
    "nb_train['full_text'] = nb_train['full_text'].astype(str)\n",
    "nb_train = nb_train[nb_train['full_text']!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "nb_val['full_text'] = nb_val['full_text'].apply(lambda x: remove_rt(x))\n",
    "nb_val['full_text'] = nb_val['full_text'].apply(lambda x: re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', x))\n",
    "nb_val['full_text'] = nb_val['full_text'].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "nb_val['full_text'] = nb_val['full_text'].apply(lambda x: x.lower())\n",
    "nb_val['full_text'] = nb_val['full_text'].apply(lambda x: remove_stop(x))\n",
    "nb_val['full_text'] = nb_val['full_text'].astype(str)\n",
    "nb_val = nb_val[nb_val['full_text']!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc:(stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "stem_vectorizer = StemmedCountVectorizer(stemmer)\n",
    "\n",
    "pipeline = Pipeline([('vect', stem_vectorizer), \n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('mnb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "clf = pipeline.fit(nb_train['full_text'], nb_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5022\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "i = 0\n",
    "\n",
    "for usr in X_val['user_id']:\n",
    "    \n",
    "    i+=1\n",
    "    clear_output()\n",
    "    print(i)\n",
    "    tweets_list = nb_val[nb_val.user_id == usr]['full_text']\n",
    "    tweets_list = tweets_list[tweets_list.notnull()]\n",
    "    if len(tweets_list[tweets_list.notnull()]) != 0:\n",
    "        pred = clf.predict_proba(tweets_list)\n",
    "        predictions.append(np.mean(pred, axis=0))\n",
    "    else:\n",
    "        predictions.append(np.array([0.2,0.2,0.2,0.2,0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.DataFrame(predictions, columns=['nb_0', 'nb_1', 'nb_2', 'nb_3', 'nb_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob['target'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob['user_id'] = X_val['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob.to_csv('data/full/predictions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = rf_prob.merge(prob, on=['user_id' , 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "stack_df = stack_df.reindex_axis(sorted(stack_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_0</th>\n",
       "      <th>nb_1</th>\n",
       "      <th>nb_2</th>\n",
       "      <th>nb_3</th>\n",
       "      <th>nb_4</th>\n",
       "      <th>rf_0</th>\n",
       "      <th>rf_1</th>\n",
       "      <th>rf_2</th>\n",
       "      <th>rf_3</th>\n",
       "      <th>rf_4</th>\n",
       "      <th>target</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>610392907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>239615243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022305</td>\n",
       "      <td>0.844103</td>\n",
       "      <td>0.065607</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.064231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>705441738391838720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.883903</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.051848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>32871086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>185036273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_0      nb_1      nb_2      nb_3      nb_4      rf_0  rf_1  rf_2  \\\n",
       "0  0.200000  0.200000  0.200000  0.200000  0.200000  0.933333   0.0   0.0   \n",
       "1  0.200000  0.200000  0.200000  0.200000  0.200000  0.966667   0.0   0.0   \n",
       "2  0.022305  0.844103  0.065607  0.003753  0.064231  0.000000   1.0   0.0   \n",
       "3  0.013702  0.883903  0.049563  0.000985  0.051848  0.000000   0.9   0.0   \n",
       "4  0.200000  0.200000  0.200000  0.200000  0.200000  0.966667   0.0   0.0   \n",
       "\n",
       "       rf_3      rf_4  target             user_id  \n",
       "0  0.033333  0.033333       0           610392907  \n",
       "1  0.033333  0.000000       0           239615243  \n",
       "2  0.000000  0.000000       1  705441738391838720  \n",
       "3  0.000000  0.100000       1            32871086  \n",
       "4  0.000000  0.033333       0           185036273  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack_df.to_csv('data/full/logreg_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metamodel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(penalty='l2', solver='saga', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validate(lr, stack_df.drop(columns=['user_id', 'target']), stack_df['target'], cv=10, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624819658554985"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = lr.fit(stack_df.drop(columns=['user_id', 'target']),  stack_df['target']).scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[0.71641791, 0.71641791, 0.96835821, 0.97791045, 0.97850746,\n",
       "         0.97970149, 0.98149254, 0.98089552, 0.98089552, 0.98089552],\n",
       "        [0.71641791, 0.71641791, 0.96537313, 0.97970149, 0.97910448,\n",
       "         0.98029851, 0.98029851, 0.98029851, 0.98029851, 0.98029851],\n",
       "        [0.71650718, 0.71650718, 0.96889952, 0.97906699, 0.98145933,\n",
       "         0.9826555 , 0.98325359, 0.98325359, 0.98325359, 0.98325359]]),\n",
       " 1: array([[0.88656716, 0.88656716, 0.88656716, 0.9838806 , 0.98686567,\n",
       "         0.98746269, 0.98746269, 0.98746269, 0.98746269, 0.98746269],\n",
       "        [0.88656716, 0.88656716, 0.88656716, 0.98746269, 0.99223881,\n",
       "         0.99402985, 0.99343284, 0.99343284, 0.99343284, 0.99343284],\n",
       "        [0.88636364, 0.88636364, 0.88636364, 0.98803828, 0.99222488,\n",
       "         0.99222488, 0.99043062, 0.99043062, 0.99043062, 0.99043062]]),\n",
       " 2: array([[0.78089552, 0.78089552, 0.96955224, 0.98149254, 0.98507463,\n",
       "         0.98567164, 0.98507463, 0.98507463, 0.98507463, 0.98507463],\n",
       "        [0.78089552, 0.78089552, 0.96238806, 0.98089552, 0.98208955,\n",
       "         0.98268657, 0.98328358, 0.9838806 , 0.9838806 , 0.9838806 ],\n",
       "        [0.78110048, 0.78110048, 0.97009569, 0.98385167, 0.98624402,\n",
       "         0.98624402, 0.98684211, 0.98684211, 0.98684211, 0.98684211]]),\n",
       " 3: array([[0.75641791, 0.75641791, 0.98268657, 0.99104478, 0.99104478,\n",
       "         0.99164179, 0.99164179, 0.99104478, 0.99104478, 0.99104478],\n",
       "        [0.75641791, 0.75641791, 0.9838806 , 0.99164179, 0.99402985,\n",
       "         0.99462687, 0.99283582, 0.99343284, 0.99343284, 0.99343284],\n",
       "        [0.75598086, 0.75598086, 0.98325359, 0.99102871, 0.99222488,\n",
       "         0.99282297, 0.99162679, 0.99282297, 0.99282297, 0.99282297]]),\n",
       " 4: array([[0.85970149, 0.85970149, 0.85970149, 0.97373134, 0.98447761,\n",
       "         0.9838806 , 0.98447761, 0.98447761, 0.98447761, 0.98447761],\n",
       "        [0.85970149, 0.85970149, 0.85970149, 0.96716418, 0.97552239,\n",
       "         0.97791045, 0.98029851, 0.98029851, 0.98029851, 0.98029851],\n",
       "        [0.86004785, 0.86004785, 0.86004785, 0.97308612, 0.9826555 ,\n",
       "         0.98444976, 0.98145933, 0.98145933, 0.98145933, 0.98145933]])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98146432, 0.00241668, 0.00450503, 0.00624864, 0.00536533]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(stack_df.drop(columns=['user_id', 'target']).iloc[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( lr, open( \"../scripts/lr.model\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
