{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets:\n",
    "#    0: porn\n",
    "#    1: propaganda\n",
    "#    2: spam\n",
    "#    3: fake followers\n",
    "#    4: genuine accounts\n",
    "\n",
    "users = pd.read_csv('data/full/users.csv', encoding='utf-8-sig')\n",
    "spam_users = pd.read_csv('data/spam/users.csv', encoding='utf-8-sig')\n",
    "\n",
    "porn_ids = users[users.target==0]['id']\n",
    "prop_ids = users[users.target==1]['id']\n",
    "spam_ids = spam_users['id']\n",
    "fake_ids = users[users.target==3]['id']\n",
    "gen_ids = users[users.target==4]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (31,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/porn/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid(tf_idf):\n",
    "\n",
    "    center = tf_idf.sum(axis=1)/tf_idf.shape[0]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_from_centroid(tf_idf, centroid):\n",
    "    \n",
    "    distances = []\n",
    "    for elem in tf_idf:\n",
    "        distances.append(np.linalg.norm(tf_idf - centroid))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wss(id):\n",
    "    \n",
    "    # get tweets per id\n",
    "    tweets = tweets_df[tweets_df.user_id == id]['full_text']\n",
    "    n_tweets = len(tweets)\n",
    "    \n",
    "    transformer = TfidfVectorizer(smooth_idf=True)\n",
    "    tf_idf = transformer.fit_transform(tweets).todense()\n",
    "    \n",
    "    centroid = compute_centroid(tf_idf)\n",
    "    distances = dist_from_centroid(tf_idf, centroid)\n",
    "    avg_dist = np.asarray(distances).sum()/n_tweets\n",
    "    \n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for user in porn_ids:\n",
    "    try:\n",
    "        distances.append(wss(user))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        distances.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (1,8,18,20,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "porn_tweets_df = pd.read_csv('data/porn/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "prop_tweets_df = pd.read_csv('data/propaganda/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "spam_tweets_df = pd.read_csv('data/spam/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "fake_tweets_df = pd.read_csv('data/fake_followers/tweets.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def get_main_words(tweets_df):\n",
    "    \n",
    "    n_words = 26\n",
    "    tweets = tweets_df['full_text'].values.astype('str')\n",
    "    \n",
    "    #tokenize and remove stop words \n",
    "    punctuation = list(string.punctuation)\n",
    "    stopWords = stopwords.words('english') + stopwords.words('italian') + stopwords.words('french') + stopwords.words('spanish') + punctuation + ['...', '\"the', \"i'm\", 'go', 'time', 'get', 'rt', 'via', '&amp;'] + [\"it's\"]\n",
    "\n",
    "    word_counter = Counter()\n",
    "    for elem in tweets:\n",
    "        word_counter.update(elem.lower().split())\n",
    "    \n",
    "    for word in stopWords:\n",
    "        if word in word_counter:\n",
    "            del word_counter[word]\n",
    "            \n",
    "\n",
    "    main_words = pd.DataFrame(data=word_counter.most_common(n_words), index=None, columns=['word', 'score'])\n",
    "    \n",
    "    # normalize scores\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    main_words['score'] = pd.DataFrame(scaler.fit_transform(main_words.score.values.reshape(-1, 1)))\n",
    "    \n",
    "    print(main_words[:25])\n",
    "    \n",
    "    return main_words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word     score\n",
      "0       love  1.000000\n",
      "1        new  0.482651\n",
      "2       like  0.439875\n",
      "3       look  0.427942\n",
      "4        one  0.356343\n",
      "5        bio  0.233156\n",
      "6       good  0.206903\n",
      "7      never  0.189279\n",
      "8        see  0.151643\n",
      "9     people  0.151092\n",
      "10  @youtube  0.133284\n",
      "11      want  0.131999\n",
      "12       day  0.115660\n",
      "13      need  0.098036\n",
      "14     today  0.093997\n",
      "15     check  0.091059\n",
      "16     great  0.087571\n",
      "17         2  0.057279\n",
      "18        us  0.048834\n",
      "19      know  0.047916\n",
      "20     happy  0.036534\n",
      "21      make  0.021663\n",
      "22    follow  0.013402\n",
      "23      best  0.013218\n",
      "24     first  0.007160\n",
      "                 word     score\n",
      "0               trump  1.000000\n",
      "1           president  0.436308\n",
      "2   @realdonaldtrump:  0.269300\n",
      "3              people  0.223744\n",
      "4                like  0.201323\n",
      "5    @realdonaldtrump  0.198466\n",
      "6                 one  0.167816\n",
      "7                  us  0.143656\n",
      "8               obama  0.122663\n",
      "9               would  0.093969\n",
      "10                new  0.069809\n",
      "11              trade  0.066952\n",
      "12               know  0.043382\n",
      "13               want  0.042761\n",
      "14            trudeau  0.039594\n",
      "15            america  0.036085\n",
      "16   @realjameswoods:  0.032638\n",
      "17              great  0.023974\n",
      "18               news  0.023881\n",
      "19           american  0.021241\n",
      "20               it’s  0.021024\n",
      "21              going  0.012391\n",
      "22               make  0.009782\n",
      "23              media  0.007857\n",
      "24              think  0.000186\n",
      "       word     score\n",
      "0      best  1.000000\n",
      "1      like  0.956552\n",
      "2       lol  0.641351\n",
      "3       one  0.516768\n",
      "4    follow  0.484269\n",
      "5      know  0.473897\n",
      "6     music  0.450847\n",
      "7        ??  0.447620\n",
      "8      cool  0.429987\n",
      "9     never  0.418232\n",
      "10     song  0.400599\n",
      "11     make  0.395067\n",
      "12     life  0.356344\n",
      "13     need  0.356344\n",
      "14   people  0.327072\n",
      "15     love  0.278322\n",
      "16     want  0.238562\n",
      "17    great  0.201222\n",
      "18      man  0.165264\n",
      "19     good  0.118128\n",
      "20   things  0.107410\n",
      "21   always  0.105682\n",
      "22  #talnts  0.031001\n",
      "23    think  0.005301\n",
      "24    going  0.003688\n",
      "             word     score\n",
      "0   #дешевоайфон5  1.000000\n",
      "1               в  0.655556\n",
      "2           айфон  0.523111\n",
      "3              :)  0.510444\n",
      "4              на  0.426000\n",
      "5            love  0.407778\n",
      "6               и  0.367778\n",
      "7            like  0.322222\n",
      "8              не  0.299333\n",
      "9             new  0.282444\n",
      "10           good  0.198222\n",
      "11              u  0.152222\n",
      "12              é  0.146000\n",
      "13              q  0.120000\n",
      "14          video  0.072889\n",
      "15            one  0.055778\n",
      "16              я  0.032000\n",
      "17              а  0.031778\n",
      "18             :d  0.024667\n",
      "19         follow  0.024444\n",
      "20         people  0.016667\n",
      "21              2  0.011778\n",
      "22            day  0.008222\n",
      "23              с  0.002444\n",
      "24             na  0.002444\n"
     ]
    }
   ],
   "source": [
    "porn_vocabulary = get_main_words(porn_tweets_df)\n",
    "porn_vocabulary.to_csv('data/porn/main_words.csv', encoding='utf-8-sig')\n",
    "prop_vocabulary = get_main_words(prop_tweets_df)\n",
    "prop_vocabulary.to_csv('data/propaganda/main_words.csv', encoding='utf-8-sig')\n",
    "spam_vocabulary = get_main_words(spam_tweets_df)\n",
    "spam_vocabulary.to_csv('data/spam/main_words.csv', encoding='utf-8-sig')\n",
    "fake_vocabulary = get_main_words(fake_tweets_df)\n",
    "fake_vocabulary.to_csv('data/fake_followers/main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "porn_words = pd.read_csv('data/porn/main_words.csv', sep=',')\n",
    "prop_words = pd.read_csv('data/propaganda/main_words.csv', sep=',')\n",
    "spam_words = pd.read_csv('data/spam/main_words.csv', sep=',')\n",
    "fake_words = pd.read_csv('data/fake_followers/main_words.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(tweets):\n",
    "\n",
    "    user_score = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # check for words in main_words and compute the scores for each tweet and for each category\n",
    "        mask = np.in1d(porn_words.word, tweet.split())\n",
    "        porn_score = porn_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(prop_words.word, tweet.split())\n",
    "        prop_score = prop_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(spam_words.word, tweet.split())\n",
    "        spam_score = spam_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(fake_words.word, tweet.split())\n",
    "        fake_score = fake_words.loc[mask]['score'].values.sum()\n",
    "        user_score = user_score.append(pd.DataFrame({'porn_words_score': porn_score, 'prop_words_score': prop_score, 'spam_words_score': spam_score,'fake_words_score': fake_score}, index=[0]), ignore_index=True)\n",
    "\n",
    "    return user_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(tweets_df, id):\n",
    "    \n",
    "    tweets = tweets_df[tweets_df.user_id == id]['full_text']\n",
    "    if len(tweets) > 0:\n",
    "        # sum all the scores of each category\n",
    "        user_score = compute_score(tweets).sum()\n",
    "        scores = np.divide(user_score,len(tweets))\n",
    "    else:\n",
    "        scores = np.array([0,0,0,0])\n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "2000 users processed\n",
      "2100 users processed\n",
      "2200 users processed\n",
      "2300 users processed\n",
      "2400 users processed\n",
      "2500 users processed\n",
      "2600 users processed\n",
      "2700 users processed\n",
      "2800 users processed\n",
      "2900 users processed\n",
      "3000 users processed\n",
      "3100 users processed\n",
      "3200 users processed\n",
      "3300 users processed\n",
      "3400 users processed\n",
      "3500 users processed\n",
      "3600 users processed\n",
      "3700 users processed\n"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'user_id'])\n",
    "i = 0\n",
    "for user_id in porn_ids:\n",
    "    i += 1\n",
    "    scores = score(porn_tweets_df, user_id)\n",
    "    temp_df = pd.DataFrame(data=[scores])\n",
    "    temp_df['user_id'] = user_id\n",
    "    score_df = score_df.append(temp_df)\n",
    "    if (i%100 == 0):\n",
    "        print(str(i) + \" users processed\")\n",
    "score_df.to_csv('data/porn/context_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "2000 users processed\n",
      "2100 users processed\n",
      "2200 users processed\n",
      "2300 users processed\n",
      "2400 users processed\n",
      "2500 users processed\n",
      "2600 users processed\n",
      "2700 users processed\n",
      "2800 users processed\n",
      "2900 users processed\n",
      "3000 users processed\n",
      "3100 users processed\n",
      "3200 users processed\n",
      "3300 users processed\n"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'user_id'])\n",
    "i = 0\n",
    "for user_id in prop_ids:\n",
    "    i += 1\n",
    "    scores = score(prop_tweets_df, user_id)\n",
    "    temp_df = pd.DataFrame(data=[scores])\n",
    "    temp_df['user_id'] = user_id\n",
    "    score_df = score_df.append(temp_df)\n",
    "    if (i%100 == 0):\n",
    "        clear_output()\n",
    "        print(str(i) + \" users processed\")\n",
    "score_df.to_csv('data/propaganda/context_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_ids.drop(3399, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 users processed\n"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'user_id'])\n",
    "i = 0\n",
    "for user_id in spam_ids:\n",
    "    i += 1\n",
    "    scores = score(spam_tweets_df, user_id)\n",
    "    temp_df = pd.DataFrame(data=[scores])\n",
    "    temp_df['user_id'] = user_id\n",
    "    score_df = score_df.append(temp_df)\n",
    "    if (i%100 == 0):\n",
    "        clear_output()\n",
    "        print(str(i) + \" users processed\")\n",
    "        \n",
    "score_df.to_csv('data/spam/context_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets_df = fake_tweets_df.rename(columns={'text': 'full_text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets_df['full_text'] = fake_tweets_df['full_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-d0c3be57254d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfake_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_tweets_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-290-3dff8219b6da>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(tweets_df, id)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# sum all the scores of each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0muser_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-289-5e5521d95b84>\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# check for words in main_words and compute the scores for each tweet and for each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mporn_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mporn_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mporn_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'user_id'])\n",
    "i = 0\n",
    "for user_id in fake_ids:\n",
    "    i += 1\n",
    "    scores = score(fake_tweets_df, user_id)\n",
    "    temp_df = pd.DataFrame(data=[scores])\n",
    "    temp_df['user_id'] = user_id\n",
    "    score_df = score_df.append(temp_df)\n",
    "    if (i%100 == 0):\n",
    "        clear_output()\n",
    "        print(str(i) + \" users processed\")\n",
    "        \n",
    "score_df.to_csv('data/fake/context_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
