{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/bot_or_not/bot/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_users = pd.read_csv('data/bot_or_not/bot_users.csv', encoding='utf-8-sig')\n",
    "gen_users = pd.read_csv('data/bot_or_not/gen_users.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_ids = bot_users['id']\n",
    "gen_ids = gen_users['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets:\n",
    "#    0: porn\n",
    "#    1: propaganda\n",
    "#    2: spam\n",
    "#    3: fake followers\n",
    "#    4: genuine accounts\n",
    "\n",
    "porn_users = pd.read_csv('data/porn/users.csv', encoding='utf-8-sig')\n",
    "prop_users = pd.read_csv('data/propaganda/users.csv', encoding='utf-8-sig')\n",
    "spam_users = pd.read_csv('data/spam/users.csv', encoding='utf-8-sig')\n",
    "fake_users = pd.read_csv('data/fake_followers/users.csv', encoding='utf-8-sig')\n",
    "genuine_users = pd.read_csv('data/genuine/users.csv', encoding='utf-8-sig')\n",
    "\n",
    "porn_ids = porn_users['id']\n",
    "prop_ids = prop_users['id']\n",
    "spam_ids = spam_users['id']\n",
    "fake_ids = fake_users['id']\n",
    "gen_ids = genuine_users['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid(tf_idf):\n",
    "\n",
    "    center = tf_idf.sum(axis=1)/tf_idf.shape[0]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_from_centroid(tf_idf, centroid):\n",
    "    \n",
    "    distances = []\n",
    "    for elem in tf_idf:\n",
    "        distances.append(np.linalg.norm(tf_idf - centroid))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wss(id, tweets_df, is_tweet = 1):\n",
    "    \n",
    "    if is_tweet == 1:\n",
    "        # get tweets per id\n",
    "        vector = tweets_df[tweets_df.user_id.astype(int) == int(id)]['full_text']\n",
    "        n_vectors = len(vector)\n",
    "    elif is_tweet == 0:\n",
    "        # get domains per id\n",
    "        vector = tweets_df[tweets_df.user_id.astype(int) == int(id)]['url']\n",
    "        vector = vector.fillna('').astype(str)\n",
    "        for i in range(len(vector)):\n",
    "            vector.iloc[i] = urlparse(vector.iloc[i]).netloc\n",
    "        n_vectors = len(vector)\n",
    "    else:\n",
    "        print ('Invalid Input')\n",
    "\n",
    "    transformer = TfidfVectorizer(smooth_idf=True)\n",
    "    tf_idf = transformer.fit_transform(vector).todense()\n",
    "    \n",
    "    centroid = compute_centroid(tf_idf)\n",
    "    distances = dist_from_centroid(tf_idf, centroid)\n",
    "    avg_dist = np.asarray(distances).sum()/n_vectors\n",
    "    \n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intradistance(bot_ids, bot_type, is_tweet=1):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "    \n",
    "    distances = []\n",
    "    i=0\n",
    "    for user in bot_ids:\n",
    "        i += 1\n",
    "        try:\n",
    "            distances.append(wss(user, tweets_df, is_tweet))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            distances.append(0)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "    \n",
    "    dist = pd.DataFrame()\n",
    "    dist['user_id'] = bot_ids.values\n",
    "    if is_tweet == 1:\n",
    "        dist['tweet_intradistance'] = distances\n",
    "        dist.to_csv('data/' + bot_type + '/tweet_intradistance.csv', index=False)\n",
    "    elif is_tweet == 0:\n",
    "        dist['url_intradistance'] = distances\n",
    "        dist.to_csv('data/' + bot_type + '/url_intradistance.csv', index=False)\n",
    "    else:\n",
    "        print ('Invalid Input')\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290 bot_or_not/bot bots processed\n",
      "bot_or_not/bot done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(bot_ids, 'bot_or_not/bot', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290 bot_or_not/bot bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "bot_or_not/bot done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(bot_ids, 'bot_or_not/bot', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160 bot_or_not/gen bots processed\n",
      "bot_or_not/gen done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(gen_ids, 'bot_or_not/gen', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160 bot_or_not/gen bots processed\n",
      "bot_or_not/gen done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(gen_ids, 'bot_or_not/gen', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(spam_ids, 'spam', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(spam_ids, 'spam', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intradistance(fake_ids, 'fake_followers', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9050 fake_followers bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(fake_ids, 'fake_followers', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(prop_ids, 'propaganda', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(prop_ids, 'propaganda', is_tweet=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660 genuine bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "genuine done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(gen_ids, 'genuine', is_tweet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660 genuine bots processed\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "genuine done!\n"
     ]
    }
   ],
   "source": [
    "intradistance(gen_ids, 'genuine', is_tweet=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "bot_tweets_df = pd.read_csv('data/bot_or_not/bot/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "gen_tweets_df = pd.read_csv('data/bot_or_not/gen/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,4,8,11,18,19,20,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "porn_tweets_df = pd.read_csv('data/porn/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "prop_tweets_df = pd.read_csv('data/propaganda/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "spam_tweets_df = pd.read_csv('data/spam/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "fake_tweets_df = pd.read_csv('data/fake_followers/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "genuine_tweets_df = pd.read_csv('data/genuine/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def get_main_words(tweets_df):\n",
    "    \n",
    "    n_words = 300\n",
    "    tweets = tweets_df['full_text'].values.astype('str')\n",
    "    \n",
    "    #tokenize and remove stop words \n",
    "    punctuation = list(string.punctuation)\n",
    "    stopWords = stopwords.words('english') + stopwords.words('italian') + stopwords.words('french') + stopwords.words('spanish') + punctuation + ['...', '\"the', \"i'm\", 'go', 'time', 'get', 'rt', 'via', '&amp;'] + [\"it's\"]\n",
    "\n",
    "    word_counter = Counter()\n",
    "    for elem in tweets:\n",
    "        word_counter.update(elem.lower().split())\n",
    "    \n",
    "    for word in stopWords:\n",
    "        if word in word_counter:\n",
    "            del word_counter[word]\n",
    "            \n",
    "\n",
    "    main_words = pd.DataFrame(data=word_counter.most_common(n_words), index=None, columns=['word', 'score'])\n",
    "    \n",
    "    return main_words[:n_words-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vocabularies():\n",
    "    porn_voc = pd.read_csv('data/porn/main_words.csv', sep=',')\n",
    "    prop_voc = pd.read_csv('data/propaganda/main_words.csv', sep=',')\n",
    "    spam_voc = pd.read_csv('data/spam/main_words.csv', sep=',')\n",
    "    fake_voc = pd.read_csv('data/fake_followers/main_words.csv', sep=',')\n",
    "    genuine_voc = pd.read_csv('data/genuine/main_words.csv', sep=',')\n",
    "    \n",
    "    porn_words = set(porn_voc['word'])\n",
    "    porn_main_words = set(porn_voc['word'][:50])\n",
    "    prop_words = set(prop_voc['word'])\n",
    "    prop_main_words = set(prop_voc['word'][:50])\n",
    "    spam_words = set(spam_voc['word'])\n",
    "    spam_main_words = set(spam_voc['word'][:50])\n",
    "    fake_words = set(fake_voc['word'])\n",
    "    fake_main_words = set(fake_voc['word'][:50])\n",
    "    genuine_words = set(genuine_voc['word'])\n",
    "    genuine_main_words = set(genuine_voc['word'][:50])\n",
    "    \n",
    "    new_porn_words = porn_words - set(prop_main_words | spam_main_words | fake_main_words | genuine_main_words)\n",
    "    new_prop_words = prop_words - set(porn_main_words | spam_main_words | fake_main_words | genuine_main_words)\n",
    "    new_spam_words = spam_words - set(prop_main_words | porn_main_words | fake_main_words | genuine_main_words)\n",
    "    new_fake_words = fake_words - set(prop_main_words | spam_main_words | porn_main_words | genuine_main_words)\n",
    "    new_genuine_words = genuine_words - set(prop_main_words | spam_main_words | porn_main_words | fake_main_words)\n",
    "    \n",
    "    print(str(len(new_porn_words)) + ' porn words')\n",
    "    print(str(len(new_prop_words)) + ' prop words')\n",
    "    print(str(len(new_spam_words)) + ' spam words')\n",
    "    print(str(len(new_fake_words)) + ' fake words')\n",
    "    print(str(len(new_genuine_words)) + ' genuine words')\n",
    "    \n",
    "    # normalize scores\n",
    "    porn_voc = porn_voc[porn_voc['word'].isin(list(new_porn_words))]\n",
    "    scaler = MinMaxScaler() \n",
    "    porn_voc['score'] = scaler.fit_transform(porn_voc.score.values.reshape(-1, 1))\n",
    "    porn_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    porn_voc.drop(porn_voc.tail(1).index, inplace=True)\n",
    "    porn_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    prop_voc = prop_voc[prop_voc['word'].isin(list(new_prop_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    prop_voc['score'] = scaler.fit_transform(prop_voc.score.values.reshape(-1, 1))\n",
    "    prop_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    prop_voc.drop(prop_voc.tail(1).index, inplace=True)\n",
    "    prop_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spam_voc = spam_voc[spam_voc['word'].isin(list(new_spam_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    spam_voc['score'] = scaler.fit_transform(spam_voc.score.values.reshape(-1, 1))\n",
    "    spam_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    spam_voc.drop(spam_voc.tail(1).index, inplace=True)\n",
    "    spam_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    fake_voc = fake_voc[fake_voc['word'].isin(list(new_fake_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    fake_voc['score'] = scaler.fit_transform(fake_voc.score.values.reshape(-1, 1))\n",
    "    fake_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    fake_voc.drop(fake_voc.tail(1).index, inplace=True)\n",
    "    fake_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    genuine_voc = genuine_voc[genuine_voc['word'].isin(list(new_genuine_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    genuine_voc['score'] = scaler.fit_transform(genuine_voc.score.values.reshape(-1, 1))\n",
    "    genuine_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    genuine_voc.drop(genuine_voc.tail(1).index, inplace=True)\n",
    "    genuine_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    porn_voc.to_csv('data/porn/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    prop_voc.to_csv('data/propaganda/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    spam_voc.to_csv('data/spam/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    fake_voc.to_csv('data/fake_followers/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    genuine_voc.to_csv('data/genuine/filtered_main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_bot_not_vocabularies():\n",
    "    bot_voc = pd.read_csv('data/bot_or_not/bot/main_words.csv', sep=',')\n",
    "    gen_voc = pd.read_csv('data/bot_or_not/gen/main_words.csv', sep=',')\n",
    "    \n",
    "    bot_words = set(bot_voc['word'])\n",
    "    bot_main_words = set(bot_voc['word'][:50])\n",
    "    gen_words = set(gen_voc['word'])\n",
    "    gen_main_words = set(gen_voc['word'][:50])\n",
    "\n",
    "    \n",
    "    new_bot_words = bot_words - set(gen_main_words)\n",
    "    new_gen_words = gen_words - set(bot_main_words)\n",
    "    \n",
    "    print(str(len(new_bot_words)) + ' bot words')\n",
    "    print(str(len(new_gen_words)) + ' gen words')\n",
    "    \n",
    "    # normalize scores\n",
    "    bot_voc = bot_voc[bot_voc['word'].isin(list(new_bot_words))]\n",
    "    scaler = MinMaxScaler() \n",
    "    bot_voc['score'] = scaler.fit_transform(bot_voc.score.values.reshape(-1, 1))\n",
    "    bot_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    bot_voc.drop(bot_voc.tail(1).index, inplace=True)\n",
    "    bot_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    gen_voc = gen_voc[gen_voc['word'].isin(list(new_gen_words))]\n",
    "    scaler = MinMaxScaler()\n",
    "    gen_voc['score'] = scaler.fit_transform(gen_voc.score.values.reshape(-1, 1))\n",
    "    gen_voc.drop(columns='Unnamed: 0', inplace=True)\n",
    "    gen_voc.drop(gen_voc.tail(1).index, inplace=True)\n",
    "    gen_voc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    bot_voc.to_csv('data/bot_or_not/bot/filtered_main_words.csv', encoding='utf-8-sig')\n",
    "    gen_voc.to_csv('data/bot_or_not/gen/filtered_main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_vocabulary = get_main_words(bot_tweets_df)\n",
    "bot_vocabulary.to_csv('data/bot_or_not/bot/main_words.csv', encoding='utf-8-sig')\n",
    "gen_vocabulary = get_main_words(gen_tweets_df)\n",
    "gen_vocabulary.to_csv('data/bot_or_not/gen/main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_vocabulary = get_main_words(porn_tweets_df)\n",
    "porn_vocabulary.to_csv('data/porn/main_words.csv', encoding='utf-8-sig')\n",
    "prop_vocabulary = get_main_words(prop_tweets_df)\n",
    "prop_vocabulary.to_csv('data/propaganda/main_words.csv', encoding='utf-8-sig')\n",
    "spam_vocabulary = get_main_words(spam_tweets_df)\n",
    "spam_vocabulary.to_csv('data/spam/main_words.csv', encoding='utf-8-sig')\n",
    "fake_vocabulary = get_main_words(fake_tweets_df)\n",
    "fake_vocabulary.to_csv('data/fake_followers/main_words.csv', encoding='utf-8-sig')\n",
    "genuine_vocabulary = get_main_words(genuine_tweets_df)\n",
    "genuine_vocabulary.to_csv('data/genuine/main_words.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 bot words\n",
      "252 gen words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "unique_bot_not_vocabularies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Context Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_words = pd.read_csv('data/bot_or_not/bot/filtered_main_words.csv', sep=',')\n",
    "gen_words = pd.read_csv('data/bot_or_not/gen/filtered_main_words.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_words = pd.read_csv('data/porn/filtered_main_words.csv', sep=',')\n",
    "prop_words = pd.read_csv('data/propaganda/filtered_main_words.csv', sep=',')\n",
    "spam_words = pd.read_csv('data/spam/filtered_main_words.csv', sep=',')\n",
    "fake_words = pd.read_csv('data/fake_followers/filtered_main_words.csv', sep=',')\n",
    "genuine_words = pd.read_csv('data/genuine/filtered_main_words.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bot_not_score(tweets):\n",
    "\n",
    "    user_score = pd.DataFrame(columns=['bot_words_score', 'gen_words_score'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # check for words in main_words and compute the scores for each tweet and for each category\n",
    "        mask = np.in1d(bot_words.word, tweet.split())\n",
    "        bot_score = bot_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(gen_words.word, tweet.split())\n",
    "        gen_score = gen_words.loc[mask]['score'].values.sum()\n",
    "        \n",
    "        user_score = user_score.append(pd.DataFrame({'bot_words_score': bot_score, 'gen_words_score': gen_score}, index=[0]), ignore_index=True)\n",
    "\n",
    "    return user_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(tweets):\n",
    "\n",
    "    user_score = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # check for words in main_words and compute the scores for each tweet and for each category\n",
    "        mask = np.in1d(porn_words.word, tweet.split())\n",
    "        porn_score = porn_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(prop_words.word, tweet.split())\n",
    "        prop_score = prop_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(spam_words.word, tweet.split())\n",
    "        spam_score = spam_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(fake_words.word, tweet.split())\n",
    "        fake_score = fake_words.loc[mask]['score'].values.sum()\n",
    "        mask = np.in1d(genuine_words.word, tweet.split())\n",
    "        genuine_score = genuine_words.loc[mask]['score'].values.sum()\n",
    "        \n",
    "        user_score = user_score.append(pd.DataFrame({'porn_words_score': porn_score, 'prop_words_score': prop_score, 'spam_words_score': spam_score,'fake_words_score': fake_score,'genuine_words_score': genuine_score}, index=[0]), ignore_index=True)\n",
    "\n",
    "    return user_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_not_score(tweets_df, id):\n",
    "    \n",
    "    tweets = tweets_df[tweets_df.user_id.astype(int) == int(id)]['full_text']\n",
    "    if len(tweets) > 0:\n",
    "        # sum all the scores of each category\n",
    "        user_score = compute_bot_not_score(tweets).sum()\n",
    "        scores = np.divide(user_score,len(tweets))\n",
    "    else:\n",
    "        scores = pd.DataFrame({'bot_words_score': 0, 'gen_words_score': 0}, index=[0])\n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(tweets_df, id):\n",
    "    \n",
    "    tweets = tweets_df[tweets_df.user_id == id]['full_text']\n",
    "    if len(tweets) > 0:\n",
    "        # sum all the scores of each category\n",
    "        user_score = compute_score(tweets).sum()\n",
    "        scores = np.divide(user_score,len(tweets))\n",
    "    else:\n",
    "        scores = pd.DataFrame({'porn_words_score': 0, 'prop_words_score': 0, 'spam_words_score': 0, 'fake_words_score': 0, 'genuine_words_score': 0}, index=[0])\n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_bot_not_score(bot_ids, bot_type):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "        \n",
    "    score_df = pd.DataFrame(columns=['bot_words_score', 'gen_words_score', 'user_id'])\n",
    "    i = 0\n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        scores = bot_not_score(tweets_df, user_id)\n",
    "        score_df = score_df.append(scores, ignore_index=True)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "    \n",
    "    score_df['user_id'] = bot_ids.values\n",
    "    \n",
    "    score_df.reset_index(drop=True, inplace=True)\n",
    "    score_df.to_csv('data/' + bot_type + '/context_score.csv', index=False)\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_score(bot_ids, bot_type):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "        \n",
    "    score_df = pd.DataFrame(columns=['porn_words_score', 'prop_words_score', 'spam_words_score', 'fake_words_score', 'genuine_words_score', 'user_id'])\n",
    "    i = 0\n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        scores = score(tweets_df, user_id)\n",
    "        score_df = score_df.append(scores, ignore_index=True)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "    \n",
    "    score_df['user_id'] = bot_ids.values\n",
    "    \n",
    "    score_df.reset_index(drop=True, inplace=True)\n",
    "    score_df.to_csv('data/' + bot_type + '/context_score.csv', index=False)\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_bot_not_score(gen_ids, 'bot_or_not/gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2907: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/pandas/core/ops.py:1167: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5a3a50768365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext_bot_not_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbot_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bot_or_not/bot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-9125297cffd8>\u001b[0m in \u001b[0;36mcontext_bot_not_score\u001b[0;34m(bot_ids, bot_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbot_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbot_not_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mscore_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-55917459e909>\u001b[0m in \u001b[0;36mbot_not_score\u001b[0;34m(tweets_df, id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbot_not_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# sum all the scores of each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "context_bot_not_score(bot_ids, 'bot_or_not/bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "context_score(prop_ids, 'propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360 spam bots processed\n",
      "spam done!\n"
     ]
    }
   ],
   "source": [
    "context_score(spam_ids, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9050 fake_followers bots processed\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "context_score(fake_ids, 'fake_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660 genuine bots processed\n",
      "genuine done!\n"
     ]
    }
   ],
   "source": [
    "context_score(gen_ids, 'genuine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tweets(tweets):\n",
    "    \n",
    "    ret_perc, media_perc, url_perc, quote_perc = tweet_perc(tweets)\n",
    "    \n",
    "    avg_len, avg_ret, avg_fav, avg_hash = tweet_desc(tweets, 'avg')\n",
    "    max_len, max_ret, max_fav, max_hash = tweet_desc(tweets, 'max')\n",
    "    min_len, min_ret, min_fav, min_hash = tweet_desc(tweets, 'min')\n",
    "    \n",
    "    freq = tweet_freq(tweets)\n",
    "\n",
    "    frame = np.array([avg_len, max_len, min_len, avg_ret, max_ret, min_ret, avg_fav, max_fav, min_fav, avg_hash, max_hash, min_hash, freq, ret_perc, media_perc, url_perc, quote_perc])\n",
    "   \n",
    "    desc_features = pd.DataFrame({'avg_len': avg_len, 'max_len': max_len, 'min_len': min_len, 'avg_ret': avg_ret, 'max_ret': max_ret, 'min_ret': min_ret, 'avg_fav': avg_fav, 'max_fav': max_fav, 'min_fav': min_fav, 'avg_hash' : avg_hash, 'max_hash' : max_hash, 'min_hash' : max_hash,'freq': freq, 'ret_perc': ret_perc, 'media_perc': media_perc, 'url_perc': url_perc, 'quote_perc': quote_perc}, index=[0])\n",
    "    \n",
    "    return desc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_perc(tweets):\n",
    "    \n",
    "    ret_perc = np.invert(tweets.retweeted_status.isnull()).sum()/len(tweets)\n",
    "    media_perc = np.invert(tweets.extended_entities.isnull()).sum()/len(tweets)\n",
    "    url_perc = np.invert(tweets.url.isnull()).sum()/len(tweets)\n",
    "    quote_perc = tweets.is_quote_status.sum()/len(tweets)\n",
    "    \n",
    "    return ret_perc, media_perc, url_perc, quote_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_count(tweets):\n",
    "    \n",
    "    occurrences = []\n",
    "    for tweet in tweets:\n",
    "        occurrences.append(tweet.count('#'))\n",
    "        \n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_desc(tweets, metric):\n",
    "    \n",
    "    tweets_lenght = tweets['full_text'].apply(lambda x: len(x))\n",
    "    \n",
    "    if metric == 'avg':\n",
    "        ret = np.mean(tweets.retweet_count)\n",
    "        lenght = np.mean(tweets_lenght)\n",
    "        fav = np.mean(tweets.favorite_count)\n",
    "        hashtag = np.mean(hashtag_count(tweets['full_text']))\n",
    "    elif metric == 'max':\n",
    "        ret = max(tweets.retweet_count)\n",
    "        lenght = max(tweets_lenght)\n",
    "        fav = max(tweets.favorite_count)\n",
    "        hashtag = max(hashtag_count(tweets['full_text']))\n",
    "    elif metric == 'min':\n",
    "        ret = min(tweets.retweet_count)\n",
    "        lenght = min(tweets_lenght)\n",
    "        fav = min(tweets.favorite_count)\n",
    "        hashtag = min(hashtag_count(tweets['full_text']))\n",
    "\n",
    "    return lenght, ret, fav, hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_freq(tweets):\n",
    "    \n",
    "    dates = list(tweets.created_at)\n",
    "    \n",
    "    last = dates[0]\n",
    "    d = last[8:10]\n",
    "    m = last[4:7]\n",
    "    y = last[-4:]\n",
    "    date = d + ' ' + m + ' ' + y\n",
    "    last = datetime.strptime(date, '%d %b %Y')\n",
    "    \n",
    "    first = dates[-1]\n",
    "    d = first[8:10]\n",
    "    m = first[4:7]\n",
    "    y = first[-4:]\n",
    "    date = d + ' ' + m + ' ' + y\n",
    "    first = datetime.strptime(date, '%d %b %Y')\n",
    "    \n",
    "    delta = (last - first).days + 1\n",
    "    freq = len(tweets)/delta\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(tweets_df, id):\n",
    "    \n",
    "    try:\n",
    "        tweets = tweets_df[tweets_df.user_id.astype(int) == int(id)]\n",
    "\n",
    "    \n",
    "        if len(tweets) > 0:\n",
    "            # sum all the scores of each category\n",
    "            features = describe_tweets(tweets)\n",
    "        else:\n",
    "            features = pd.DataFrame({'avg_len': 0, 'max_len': 0, 'min_len': 0,'avg_ret': 0, 'max_ret': 0, 'min_ret': 0, 'avg_fav': 0, 'max_fav': 0, 'min_fav': 0, 'avg_hash': 0, 'max_hash': 0, 'min_hash': 0, 'freq': 0, 'ret_perc': 0, 'media_perc': 0, 'url_perc': 0, 'quote_perc':0}, index=[0])\n",
    "\n",
    "    except:\n",
    "        features = pd.DataFrame({'avg_len': 0, 'max_len': 0, 'min_len': 0,'avg_ret': 0, 'max_ret': 0, 'min_ret': 0, 'avg_fav': 0, 'max_fav': 0, 'min_fav': 0, 'avg_hash': 0, 'max_hash': 0, 'min_hash': 0, 'freq': 0, 'ret_perc': 0, 'media_perc': 0, 'url_perc': 0, 'quote_perc':0}, index=[0])\n",
    "    \n",
    "    \n",
    "    # return the average scores of each user\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_features(bot_ids, bot_type):\n",
    "    \n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "\n",
    "        \n",
    "    desc_df = pd.DataFrame(columns=['avg_len', 'max_len', 'min_len', 'avg_ret', 'max_ret', 'min_ret', 'avg_fav', 'max_fav', 'min_fav', 'avg_hash', 'max_hash', 'min_hash', 'freq', 'ret_perc', 'media_perc', 'url_perc', 'quote_perc'])\n",
    "    i = 0\n",
    "    \n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        features = describe(tweets_df, user_id)\n",
    "        desc_df = desc_df.append(features, ignore_index=True)\n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" \" + bot_type + \" bots processed\")\n",
    "    \n",
    "    desc_df['user_id'] = bot_ids.values\n",
    "    \n",
    "    desc_df.reset_index(drop=True, inplace=True)\n",
    "    desc_df.to_csv('data/' + bot_type + '/descriptive_features.csv', index=False)\n",
    "\n",
    "    print(bot_type + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lorenzo/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/bot_or_not/bot/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3575\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for elem in bot_users.id:\n",
    "    int(elem)\n",
    "    i+=1\n",
    "    clear_output()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                             45372197\n",
       "name                                                                            Etherea\n",
       "screen_name                                                                 etherearock\n",
       "statuses_count                                                                      140\n",
       "followers_count                                                                     122\n",
       "friends_count                                                                        30\n",
       "favourites_count                                                                      0\n",
       "listed_count                                                                          8\n",
       "url                                                              http://t.co/MeKV7HVI8t\n",
       "lang                                                                                 en\n",
       "time_zone                                                                           NaN\n",
       "location                                                                       Pretoria\n",
       "default_profile                                                                   False\n",
       "default_profile_image                                                             False\n",
       "geo_enabled                                                                       False\n",
       "profile_image_url                     http://pbs.twimg.com/profile_images/508867155/...\n",
       "profile_use_background_image                                                       True\n",
       "profile_background_image_url_https    https://abs.twimg.com/images/themes/theme1/bg.png\n",
       "profile_text_color                                                               B5B5B5\n",
       "profile_image_url_https               https://pbs.twimg.com/profile_images/508867155...\n",
       "profile_sidebar_border_color                                                     1C2024\n",
       "profile_background_tile                                                           False\n",
       "profile_sidebar_fill_color                                                       3A3359\n",
       "profile_background_image_url           http://abs.twimg.com/images/themes/theme1/bg.png\n",
       "profile_background_color                                                         030303\n",
       "profile_link_color                                                               2FC2EF\n",
       "utc_offset                                                                          NaN\n",
       "is_translator                                                                     False\n",
       "follow_request_sent                                                               False\n",
       "protected                                                                         False\n",
       "verified                                                                          False\n",
       "notifications                                                                     False\n",
       "description                                                  Grunge-inspired metal band\n",
       "contributors_enabled                                                              False\n",
       "following                                                                         False\n",
       "created_at                                                          2009-06-07 16:50:13\n",
       "target                                                                                1\n",
       "Name: 3576, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_users.iloc[3575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_users.drop(bot_users.index[2596], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290 bot_or_not/bot bots processed\n",
      "bot_or_not/bot done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(bot_ids, 'bot_or_not/bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160 bot_or_not/gen bots processed\n",
      "bot_or_not/gen done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(gen_ids, 'bot_or_not/gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(prop_ids, 'propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360 spam bots processed\n",
      "spam done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(spam_ids, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9050 fake_followers bots processed\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(fake_ids, 'fake_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660 genuine bots processed\n",
      "genuine done!\n"
     ]
    }
   ],
   "source": [
    "descriptive_features(gen_ids, 'genuine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSFW Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "from ast import literal_eval\n",
    "\n",
    "# Loads label file, strips off carriage return\n",
    "label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(\"../scripts/NSFW-detection/retrained_labels.txt\")]\n",
    "\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(\"../scripts/NSFW-detection/retrained_graph.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "def nsfw(url):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, \"local-filename.jpg\")\n",
    "        image_path = 'local-filename.jpg'\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "        # Read in the image_data\n",
    "        image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # Feed the image_data as input to the graph and get first prediction\n",
    "            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "            predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "            return predictions[0][1]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsfw_detection(bot_ids, bot_type):\n",
    "    \n",
    "    users_df = pd.read_csv('data/' + bot_type + '/users.csv', encoding='utf-8-sig')\n",
    "    tweets_df = pd.read_csv('data/' + bot_type + '/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "    df = pd.DataFrame(columns=['user_id', 'nsfw_avg', 'nsfw_profile'])\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for user_id in bot_ids:\n",
    "        i += 1\n",
    "        tweets = tweets_df[tweets_df.user_id == user_id]\n",
    "        porn = 0\n",
    "        tot = len(tweets.extended_entities[tweets.extended_entities.notnull()][:10])\n",
    "        \n",
    "        for media in tweets.extended_entities[tweets.extended_entities.notnull()][:10]:\n",
    "            try:\n",
    "                python_dict = literal_eval(media)\n",
    "                url = python_dict['media'][0]['media_url_https']\n",
    "                if nsfw(url) > 0.5:\n",
    "                    porn += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "        if tot > 0:\n",
    "            nudity = porn/tot\n",
    "        else:\n",
    "            nudity = 0\n",
    "        \n",
    "        try:\n",
    "            profile = users_df[users_df.id == user_id]['profile_image_url_https'].iloc[0].replace('normal', '400x400')\n",
    "            profile_nudity = nsfw(profile)\n",
    "        except:\n",
    "            profile_nudity = 0\n",
    "            \n",
    "        \n",
    "        df = df.append({'user_id':user_id, 'nsfw_avg':nudity, 'nsfw_profile': profile_nudity}, ignore_index=True)\n",
    "        \n",
    "        if (i%10 == 0):\n",
    "            clear_output()\n",
    "            print(str(i) +  \" / \" + str(len(bot_ids)) + \" \" + bot_type + \" bots processed\")\n",
    "        \n",
    "        \n",
    "    #df.to_csv('data/' + bot_type + '/nsfw_avg.csv', index=False)\n",
    "    \n",
    "    print(bot_type + \" done!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6930 / 6935 porn bots processed\n",
      "porn done!\n"
     ]
    }
   ],
   "source": [
    "porn_nsfw = nsfw_detection(porn_ids, 'porn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 / 3372 propaganda bots processed\n",
      "propaganda done!\n"
     ]
    }
   ],
   "source": [
    "prop_nsfw = nsfw_detection(prop_ids, 'propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360 / 5361 spam bots processed\n",
      "spam done!\n"
     ]
    }
   ],
   "source": [
    "spam_nsfw = nsfw_detection(spam_ids, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9050 / 9053 fake_followers bots processed\n",
      "fake_followers done!\n"
     ]
    }
   ],
   "source": [
    "ff_nsfw = nsfw_detection(fake_ids, 'fake_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660 / 3661 genuine bots processed\n",
      "genuine done!\n"
     ]
    }
   ],
   "source": [
    "gen_nsfw = nsfw_detection(gen_ids, 'genuine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "porn_nsfw.to_csv('data/porn/nsfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_nsfw.to_csv('data/propaganda/nsfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_nsfw.to_csv('data/spam/nsfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_nsfw.to_csv('data/fake_followers/nsfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_nsfw.to_csv('data/genuine/nsfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize_tweets(tweets_df, k=5):\n",
    "    \n",
    "    tweets = tweets_df['full_text']\n",
    "    \n",
    "    transformer = TfidfVectorizer(smooth_idf=True)\n",
    "    tf_idf = transformer.fit_transform(tweets)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, verbose=True).fit(tf_idf)\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "porn = pd.read_csv('data/porn/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "news = pd.read_csv('data/propaganda/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "ff = pd.read_csv('data/fake_followers/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "spam = pd.read_csv('data/spam/tweets.csv', encoding='utf-8-sig', sep='\\t')\n",
    "gen = pd.read_csv('data/genuine/tweets.csv', encoding='utf-8-sig', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 80923.216\n",
      "Iteration  1, inertia 40994.959\n",
      "Iteration  2, inertia 40901.466\n",
      "Iteration  3, inertia 40877.730\n",
      "Iteration  4, inertia 40871.792\n",
      "Iteration  5, inertia 40870.639\n",
      "Iteration  6, inertia 40870.193\n",
      "Iteration  7, inertia 40869.459\n",
      "Iteration  8, inertia 40869.189\n",
      "Iteration  9, inertia 40868.484\n",
      "Iteration 10, inertia 40868.086\n",
      "Iteration 11, inertia 40867.866\n",
      "Iteration 12, inertia 40867.622\n",
      "Iteration 13, inertia 40867.305\n",
      "Iteration 14, inertia 40867.298\n",
      "Iteration 15, inertia 40867.297\n",
      "Converged at iteration 15: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 81451.867\n",
      "Iteration  1, inertia 40961.765\n",
      "Iteration  2, inertia 40858.838\n",
      "Iteration  3, inertia 40837.124\n",
      "Iteration  4, inertia 40824.035\n",
      "Iteration  5, inertia 40819.692\n",
      "Iteration  6, inertia 40815.136\n",
      "Iteration  7, inertia 40812.155\n",
      "Iteration  8, inertia 40810.004\n",
      "Iteration  9, inertia 40808.296\n",
      "Iteration 10, inertia 40807.175\n",
      "Iteration 11, inertia 40806.573\n",
      "Iteration 12, inertia 40806.349\n",
      "Iteration 13, inertia 40806.218\n",
      "Iteration 14, inertia 40806.030\n",
      "Iteration 15, inertia 40805.777\n",
      "Iteration 16, inertia 40805.683\n",
      "Iteration 17, inertia 40805.649\n",
      "Iteration 18, inertia 40805.642\n",
      "Iteration 19, inertia 40805.640\n",
      "Iteration 20, inertia 40805.639\n",
      "Iteration 21, inertia 40805.639\n",
      "Converged at iteration 21: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 80954.868\n",
      "Iteration  1, inertia 40909.076\n",
      "Iteration  2, inertia 40842.675\n",
      "Iteration  3, inertia 40823.867\n",
      "Iteration  4, inertia 40808.155\n",
      "Iteration  5, inertia 40798.265\n",
      "Iteration  6, inertia 40792.113\n",
      "Iteration  7, inertia 40789.329\n",
      "Iteration  8, inertia 40788.618\n",
      "Iteration  9, inertia 40788.317\n",
      "Iteration 10, inertia 40788.232\n",
      "Iteration 11, inertia 40788.187\n",
      "Iteration 12, inertia 40788.179\n",
      "Iteration 13, inertia 40788.176\n",
      "Iteration 14, inertia 40788.174\n",
      "Iteration 15, inertia 40788.173\n",
      "Iteration 16, inertia 40788.173\n",
      "Converged at iteration 16: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 81040.348\n",
      "Iteration  1, inertia 40974.842\n",
      "Iteration  2, inertia 40900.046\n",
      "Iteration  3, inertia 40866.645\n",
      "Iteration  4, inertia 40858.060\n",
      "Iteration  5, inertia 40849.458\n",
      "Iteration  6, inertia 40844.500\n",
      "Iteration  7, inertia 40843.815\n",
      "Iteration  8, inertia 40843.542\n",
      "Iteration  9, inertia 40843.463\n",
      "Iteration 10, inertia 40843.429\n",
      "Iteration 11, inertia 40843.413\n",
      "Iteration 12, inertia 40843.406\n",
      "Iteration 13, inertia 40843.403\n",
      "Iteration 14, inertia 40843.400\n",
      "Iteration 15, inertia 40843.398\n",
      "Iteration 16, inertia 40843.395\n",
      "Iteration 17, inertia 40843.394\n",
      "Iteration 18, inertia 40843.393\n",
      "Iteration 19, inertia 40843.392\n",
      "Iteration 20, inertia 40843.392\n",
      "Iteration 21, inertia 40843.391\n",
      "Converged at iteration 21: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 81224.667\n",
      "Iteration  1, inertia 41002.552\n",
      "Iteration  2, inertia 40940.678\n",
      "Iteration  3, inertia 40924.554\n",
      "Iteration  4, inertia 40918.576\n",
      "Iteration  5, inertia 40914.339\n",
      "Iteration  6, inertia 40907.755\n",
      "Iteration  7, inertia 40896.044\n",
      "Iteration  8, inertia 40891.981\n",
      "Iteration  9, inertia 40890.732\n",
      "Iteration 10, inertia 40889.826\n",
      "Iteration 11, inertia 40889.185\n",
      "Iteration 12, inertia 40888.565\n",
      "Iteration 13, inertia 40888.308\n",
      "Iteration 14, inertia 40888.258\n",
      "Iteration 15, inertia 40888.253\n",
      "Iteration 16, inertia 40888.233\n",
      "Iteration 17, inertia 40888.231\n",
      "Iteration 18, inertia 40888.230\n",
      "Iteration 19, inertia 40888.229\n",
      "Iteration 20, inertia 40888.228\n",
      "Iteration 21, inertia 40888.228\n",
      "Converged at iteration 21: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 80927.235\n",
      "Iteration  1, inertia 40935.242\n",
      "Iteration  2, inertia 40824.497\n",
      "Iteration  3, inertia 40799.697\n",
      "Iteration  4, inertia 40792.011\n",
      "Iteration  5, inertia 40789.984\n",
      "Iteration  6, inertia 40789.723\n",
      "Iteration  7, inertia 40789.613\n",
      "Iteration  8, inertia 40789.578\n",
      "Iteration  9, inertia 40789.560\n",
      "Iteration 10, inertia 40789.555\n",
      "Iteration 11, inertia 40789.553\n",
      "Iteration 12, inertia 40789.552\n",
      "Iteration 13, inertia 40789.551\n",
      "Iteration 14, inertia 40789.550\n",
      "Iteration 15, inertia 40789.549\n",
      "Iteration 16, inertia 40789.547\n",
      "Iteration 17, inertia 40789.546\n",
      "Iteration 18, inertia 40789.545\n",
      "Iteration 19, inertia 40789.545\n",
      "Converged at iteration 19: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 80876.577\n",
      "Iteration  1, inertia 40973.259\n",
      "Iteration  2, inertia 40901.907\n",
      "Iteration  3, inertia 40886.540\n",
      "Iteration  4, inertia 40878.307\n",
      "Iteration  5, inertia 40869.554\n",
      "Iteration  6, inertia 40865.267\n",
      "Iteration  7, inertia 40861.557\n",
      "Iteration  8, inertia 40858.137\n",
      "Iteration  9, inertia 40856.449\n",
      "Iteration 10, inertia 40854.788\n",
      "Iteration 11, inertia 40854.443\n",
      "Iteration 12, inertia 40853.402\n",
      "Iteration 13, inertia 40851.958\n",
      "Iteration 14, inertia 40850.959\n",
      "Iteration 15, inertia 40850.844\n",
      "Iteration 16, inertia 40850.811\n",
      "Iteration 17, inertia 40850.757\n",
      "Iteration 18, inertia 40850.756\n",
      "Iteration 19, inertia 40850.756\n",
      "Converged at iteration 19: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 80725.996\n",
      "Iteration  1, inertia 40891.928\n",
      "Iteration  2, inertia 40829.729\n",
      "Iteration  3, inertia 40813.547\n",
      "Iteration  4, inertia 40808.568\n",
      "Iteration  5, inertia 40807.190\n",
      "Iteration  6, inertia 40806.499\n",
      "Iteration  7, inertia 40806.408\n",
      "Iteration  8, inertia 40806.308\n",
      "Iteration  9, inertia 40806.237\n",
      "Iteration 10, inertia 40806.070\n",
      "Iteration 11, inertia 40806.048\n",
      "Iteration 12, inertia 40806.036\n",
      "Iteration 13, inertia 40806.016\n",
      "Iteration 14, inertia 40805.996\n",
      "Iteration 15, inertia 40805.980\n",
      "Iteration 16, inertia 40805.966\n",
      "Iteration 17, inertia 40805.955\n",
      "Iteration 18, inertia 40805.941\n",
      "Iteration 19, inertia 40805.927\n",
      "Iteration 20, inertia 40805.920\n",
      "Iteration 21, inertia 40805.919\n",
      "Iteration 22, inertia 40805.919\n",
      "Iteration 23, inertia 40805.918\n",
      "Converged at iteration 23: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 81686.434\n",
      "Iteration  1, inertia 41005.288\n",
      "Iteration  2, inertia 40910.653\n",
      "Iteration  3, inertia 40893.129\n",
      "Iteration  4, inertia 40886.040\n",
      "Iteration  5, inertia 40880.923\n",
      "Iteration  6, inertia 40878.277\n",
      "Iteration  7, inertia 40877.059\n",
      "Iteration  8, inertia 40875.746\n",
      "Iteration  9, inertia 40874.451\n",
      "Iteration 10, inertia 40872.359\n",
      "Iteration 11, inertia 40869.102\n",
      "Iteration 12, inertia 40864.391\n",
      "Iteration 13, inertia 40855.956\n",
      "Iteration 14, inertia 40851.886\n",
      "Iteration 15, inertia 40848.878\n",
      "Iteration 16, inertia 40848.550\n",
      "Iteration 17, inertia 40848.207\n",
      "Iteration 18, inertia 40848.200\n",
      "Iteration 19, inertia 40848.197\n",
      "Iteration 20, inertia 40848.197\n",
      "Converged at iteration 20: center shift 0.000000e+00 within tolerance 1.167001e-09\n",
      "Initialization complete\n",
      "Iteration  0, inertia 80751.575\n",
      "Iteration  1, inertia 40986.788\n",
      "Iteration  2, inertia 40850.189\n",
      "Iteration  3, inertia 40827.935\n",
      "Iteration  4, inertia 40824.140\n",
      "Iteration  5, inertia 40821.441\n",
      "Iteration  6, inertia 40820.832\n",
      "Iteration  7, inertia 40820.412\n",
      "Iteration  8, inertia 40820.294\n",
      "Iteration  9, inertia 40820.236\n",
      "Iteration 10, inertia 40820.184\n",
      "Iteration 11, inertia 40820.120\n",
      "Iteration 12, inertia 40820.077\n",
      "Iteration 13, inertia 40820.030\n",
      "Iteration 14, inertia 40820.000\n",
      "Iteration 15, inertia 40819.848\n",
      "Iteration 16, inertia 40819.822\n",
      "Iteration 17, inertia 40819.793\n",
      "Iteration 18, inertia 40819.765\n",
      "Iteration 19, inertia 40819.750\n",
      "Iteration 20, inertia 40819.746\n",
      "Iteration 21, inertia 40819.742\n",
      "Iteration 22, inertia 40819.739\n",
      "Iteration 23, inertia 40819.734\n",
      "Iteration 24, inertia 40819.686\n",
      "Iteration 25, inertia 40819.667\n",
      "Iteration 26, inertia 40819.628\n",
      "Iteration 27, inertia 40819.605\n",
      "Iteration 28, inertia 40819.591\n",
      "Iteration 29, inertia 40819.538\n",
      "Iteration 30, inertia 40819.526\n",
      "Iteration 31, inertia 40819.521\n",
      "Iteration 32, inertia 40819.515\n",
      "Iteration 33, inertia 40819.509\n",
      "Iteration 34, inertia 40819.504\n",
      "Iteration 35, inertia 40819.496\n",
      "Iteration 36, inertia 40819.490\n",
      "Iteration 37, inertia 40819.481\n",
      "Iteration 38, inertia 40819.478\n",
      "Iteration 39, inertia 40819.473\n",
      "Iteration 40, inertia 40819.469\n",
      "Iteration 41, inertia 40819.466\n",
      "Iteration 42, inertia 40819.462\n",
      "Iteration 43, inertia 40819.459\n",
      "Iteration 44, inertia 40819.456\n",
      "Iteration 45, inertia 40819.452\n",
      "Iteration 46, inertia 40819.449\n",
      "Iteration 47, inertia 40819.324\n",
      "Iteration 48, inertia 40819.316\n",
      "Iteration 49, inertia 40819.283\n",
      "Iteration 50, inertia 40819.272\n",
      "Iteration 51, inertia 40819.260\n",
      "Iteration 52, inertia 40819.252\n",
      "Iteration 53, inertia 40819.065\n",
      "Iteration 54, inertia 40818.855\n",
      "Iteration 55, inertia 40818.845\n",
      "Iteration 56, inertia 40818.841\n",
      "Iteration 57, inertia 40818.839\n",
      "Iteration 58, inertia 40818.837\n",
      "Iteration 59, inertia 40818.836\n",
      "Iteration 60, inertia 40818.835\n",
      "Converged at iteration 60: center shift 0.000000e+00 within tolerance 1.167001e-09\n"
     ]
    }
   ],
   "source": [
    "labels = clusterize_tweets(tweets_df, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.asarray(tweets_df['full_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweets for each target\n",
    "target_tweets = tweets[labels.labels_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tweets = \" \".join(target_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = filter(lambda x:x[0]!='#', target_tweets.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    # get all the tweets in a cluster\n",
    "    tweets[labels.labels_ == i]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
